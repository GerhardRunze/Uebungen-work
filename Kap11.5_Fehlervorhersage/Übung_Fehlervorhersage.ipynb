{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "2284b8a2-b20b-4937-a340-3e2e28eb98fc",
            "metadata": {
                "tags": []
            },
            "source": [
                "# \u00dcbungen zu Kapitel 11.5 - Einsatz von KI f\u00fcr die Fehlervorhersage\n",
                "**(Aufbau eines Fehlervorhersagesystems)**\n",
                "\n",
                "*Eine \u00dcbung zum Buch \"[Basiswissen KI-Testen - Qualit\u00e4t von und mit KI-basierten Systemen](https://dpunkt.de/produkt/basiswissen-ki-testen/)\", ISBN 978-3-86490-947-4*\n",
                "\n",
                "In dieser \u00dcbung kannst du ein Fehlervorhersagesystem trainieren, das anhand von Codemetriken prognostizieren soll, ob ein Programmcode vermutlich fehlerhaft ist oder korrekt arbeitet. Dabei wirst du viele Arbeitsschritte, die du in den vorausgegangenen \u00dcbungen kennengelernt hast, erneut anwenden: _Datenvorbereitung_, _Modellauswahl_, _Training_, _Evaluierung_, _Tuning_ und _Test_.\n",
                "\n",
                "Diese \u00dcbung besteht aus sieben Aufgaben, die aufeinander aufbauen\n",
                "* Aufgabe 1: Das Zielverstehen\n",
                "* Aufgabe 2: Algorithmus w\u00e4hlen\n",
                "* Aufgabe 3: Datenvorbereitung\n",
                "* Aufgabe 4: Aufteilen der Daten und Modellgenerierung\n",
                "* Aufgabe 5: Mehr Aufbereitung der Daten\n",
                "* Aufgabe 6: Modelle mit den zus\u00e4tzlich aufbereiteten Daten generieren\n",
                "* Aufgabe 7: Unausgeglichene Daten angleichen"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2456f2ea-3580-45fe-817e-c1506e16f632",
            "metadata": {},
            "source": [
                "Wir nutzen hier wieder verschiedene Bibliotheken mit passenden Methoden, die du bereits kennengelernt hast:\n",
                "\n",
                "[<img src=\"https://pandas.pydata.org/docs/_static/pandas.svg\" alt=\"pandas\" width=\"80\" height=\"24\">](https://pandas.pydata.org/docs/reference/index.html)\n",
                "&emsp; [<img src=\"https://seaborn.pydata.org/_static/logo-wide-lightbg.svg\" alt=\"seaborn\" width=\"100\" height=\"24\">](https://seaborn.pydata.org/)\n",
                "&emsp; [<img src=\"https://docs.scipy.org/doc/scipy/_static/logo.svg\" alt=\"SciPy\" width=\"24\" height=\"24\"> SciPy](https://docs.scipy.org/doc/scipy/index.html)\n",
                "&emsp; [<img src=\"https://scikit-learn.org/stable/_static/scikit-learn-logo-small.png\" alt=\"Scikit-learn\" width=\"80\" height=\"24\">](https://scikit-learn.org/stable/modules/classes.html)\n",
                "&emsp; [<img src=\"https://matplotlib.org/_static/logo_light.svg\" alt=\"Matplotlib\" width=\"100\" height=\"24\">](https://matplotlib.org/)\n",
                "<!-- &emsp; [<img src=\"https://numpy.org/doc/stable/_static/numpylogo.svg\" alt=\"Numpy\" width=\"80\" height=\"24\">](https://numpy.org/doc/stable/reference/index.html#reference) -->\n",
                "\n",
                "*Hinweis 1:* Wenn du das Prinzip unseres Beispiels verstanden hast, kannst du dir bei Interesse \u00fcber das GitHub Projekt [NASADefectDataset](https://github.com/klainfo/NASADefectDataset) weitere Datens\u00e4tze ansehen und diese als zus\u00e4tzliche Quelle heranziehen...\n",
                "\n",
                "*Hinweis 2:* In den folgenden Codebeispielen werden sehr h\u00e4ufig Pseudo-Zufallszahlengeneratoren eingesetzt. Damit unsere Hinweise und Kommentierungen zum Code und dessen Ergebnissen passen, belegen wir die Startwerte dieser Generatoren mit festen Werten. In echten Projekten geht man so nicht vor. F\u00fcr eine m\u00f6glichst hohe Reproduzierbarkeit in der Entwicklungskette, solltest du dann aber zumindest die zuf\u00e4lligen Startwerte protokollieren."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a00ef6e2-dc93-47d7-a4c0-229cef734835",
            "metadata": {
                "tags": [
                    "Aufgabe"
                ]
            },
            "source": [
                "## Aufgabe 1: Das Ziel verstehen\n",
                "Du sollst ein Fehlerprognosesystem f\u00fcr Softwaremodule entwickeln. Dieses soll anhand von Codemetriken, die zu einem Softwaremodul ermittelt werden, absch\u00e4tzen, ob das Softwaremodul noch Fehlerzust\u00e4nde enthalten k\u00f6nnte oder nicht. Als Grundlage dienen dir Datens\u00e4tze von Softwaremodulen mit und ohne Fehlerzust\u00e4nde, f\u00fcr die eine Reihe von Codemetriken bereits ermittelt wurden.\n",
                "\n",
                "* Welche Fragen solltest du im Vorfeld kl\u00e4ren?\n",
                "* Wie aussichtsreich vermutest du ist es, aus Codemetriken fehlerhaften Programmcode zu prognostizieren?\n",
                "\n",
                "Eine Diskussion m\u00f6glicher Antworten findest du wieder hinter der folgenden Zelle (...)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "35adb226-7a63-4eb5-bb22-c8e3264af6c4",
            "metadata": {
                "tags": [
                    "L\u00f6sung"
                ],
                "jupyter": {
                    "source_hidden": true
                }
            },
            "source": [
                "**L\u00f6sungsdiskussion:** Wichtige Fragen, die vorab mit Nutzern, Kunden, Geldgebern oder anderen Verantwortlichen oder Betroffenen gekl\u00e4rt werden sollten, sind zum Beispiel:\n",
                "* *Wie und f\u00fcr wen soll das System eingesetzt werden?*</br>\n",
                "Ist es eine Art Hinweisgeber f\u00fcr Entwickler, der vor jedem Code-Checkin erfolgt? Sollen tausende, bereits existierende Module gescannt werden? Die Vor- und Nachbereitungen k\u00f6nnen sich unterscheiden, ebenso wie eine sp\u00e4tere Einbettung in ein gr\u00f6\u00dferes Gesamtsystem. Je nach Nutzerkreis k\u00f6nnen unterschiedliche Erwartungen an die funktionale Leistung des Systems existieren.\n",
                "* *Auf welchen Codequellen soll das System eingesetzt werden?*</br>\n",
                "Welche Programmiersprachen soll das System analysieren k\u00f6nnen? Um welche Produkte und Dom\u00e4nen handelt es sich bei den Software-Quellen? Codemetriken k\u00f6nnen je nach Programmiersprache unterschiedliche Kritikalit\u00e4t f\u00fcr noch enthaltene Fehlerzust\u00e4nde signalisieren. Je nach Anwendungsgebiet k\u00f6nnen hohe oder eher niedrige Erwartungen an die funktionale Leistung gestellt werden.\n",
                "* *Welche funktionalen Leistungsmetriken sind besonders wichtig?*</br>\n",
                "Nicht jede Dom\u00e4ne und jeder Stakeholder haben die gleichen Bed\u00fcrfnisse. Manchmal ist die Genauigkeit des Systems gefragt. H\u00e4ufiger k\u00f6nnte jedoch die Sensitivit\u00e4t oder Pr\u00e4zision von gr\u00f6\u00dferer Bedeutung sein. Dies vorher zu kl\u00e4ren, kann falsch spendierten Aufwand im Tuning reduzieren.\n",
                "\n",
                "Programmcode mit Fehlerzust\u00e4nden allein aus den Codemetriken zu prognostizieren, k\u00f6nnte ein schwieriges Unterfangen sein. Beispielsweise muss eine besonders hohe [zyklomatische Komplexit\u00e4t](https://de.wikipedia.org/wiki/McCabe-Metrik) (nach McCabe) nicht gleichbedeutend mit einem Fehlerzustand sein. Die zyklomatische Komplexit\u00e4t k\u00f6nnte nach einer Fehlerkorrektur gleichgeblieben sein, weil sie nicht urs\u00e4chlich f\u00fcr den Fehler war. Eine statistische H\u00e4ufung von Fehlern bei komplexen Modulen k\u00f6nnten wir uns aber vorstellen.\n",
                "\n",
                "Entscheidend ist sicher auch, ob unsere Trainingsdaten mit Beispielen aus geeigneten Entwicklungsst\u00e4nden erhoben wurden: erste Versionen oder \"abgehangene\" Software, Code von unerfahrenen oder erfahrenen Teammitgliedern."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "34b15db5-072d-4f59-94e7-924184f2c2ec",
            "metadata": {},
            "source": [
                "## Aufgabe 2: Algorithmus ausw\u00e4hlen\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "37712245-6f46-4786-a01f-e6ecc4f9a570",
            "metadata": {
                "tags": [
                    "Aufgabe"
                ]
            },
            "source": [
                "Nimm an, aus Aufgabe 1 haben wir folgendes Ziel vereinbart: Mit mehreren bereits vorhandenen Listen von Softwaremodulen - mit und ohne bekannte Fehlerzust\u00e4nde - und ihren dazu ermittelten Codemetriken sollen wir ein Modell trainieren, das uns diejenigen Module identifizieren soll, in denen noch Fehler vermutet werden. Anhand dieser Vermutung sollen die Module nochmal einem intensiven Codereview und weiteren Tests unterzogen werden.\n",
                "\n",
                "**Aufgabe:** *Welche Art von maschinellem Lernen (ML) w\u00fcrdest du w\u00e4hlen?</br>*\n",
                "Erinnere dich an die erst Aufgabe aus [\u00dcbung zu Kapitel 3.3 - Wahl der passenden ML-Art](../Kap03.3_ML-Art_w\u00e4hlen/\u00dcbung_ML-Arten.ipynb)."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cac50cf6-81d3-4a06-b372-bcb16367dffe",
            "metadata": {
                "tags": [
                    "L\u00f6sung"
                ],
                "jupyter": {
                    "source_hidden": true
                }
            },
            "source": [
                "**L\u00f6sung:** Die Beschreibung deutet klar auf eine **Klassifikation**. Denn wir haben Trainingsdaten zur Verf\u00fcgung, zu denen die erwarteten Ergebnisse bekannt sind (mit oder ohne Fehlerzustand). Die Daten sind also bereits gekennzeichnet (annotiert/gelabelt). Als Ergebnis wird eine einfache bin\u00e4re Entscheidung, ob ein Fehlerzustand enthalten ist, erwartet: *ja* oder *nein*. Also entwickeln wir einen Klassifikator."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "228a0b2c-8b72-48f6-b579-5264c3375577",
            "metadata": {
                "tags": [],
                "toc-hr-collapsed": true
            },
            "source": [
                "## Aufgabe 3: Datenvorbereitung"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "65c6b00c-465e-46e3-a7b9-ac3b59856d8c",
            "metadata": {},
            "source": [
                "### Schritt 1: Datenbeschaffung\n",
                "*siehe auch Kapitel 4.1.1 im Buch*"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "93ab6e5d-6a20-41c9-a655-1e3bdad48719",
            "metadata": {},
            "source": [
                "Im Verzeichnis `Data/` dieser \u00dcbung findest du **drei Dateien** im _arff_-Dateiformat. Zum Laden, Bearbeiten und Visualisieren dieser Daten laden wir zun\u00e4chst die Bibliotheken: *pandas*, *seaborn*, *matplotlib* und *scipy* (letztere, damit wir das *arff*-Datenformat lesen k\u00f6nnen). Einige brauchen wir aber erst sp\u00e4ter."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6d82505d-a341-488f-a8bf-e91817123d45",
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "import pandas            as pd\n",
                "import seaborn           as sns\n",
                "import matplotlib.pyplot as plt\n",
                "from   scipy.io      import arff"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6c65b29f-88a7-4004-bf9a-ab0722deeac4",
            "metadata": {},
            "source": [
                "Mit der oben von *scipy* importierten Klasse [arff](https://docs.scipy.org/doc/scipy/reference/io.html#module-scipy.io.arff) kannst du mit der Methode [loadarff](https://docs.scipy.org/doc/scipy/reference/generated/scipy.io.arff.loadarff.html#scipy.io.arff.loadarff) jeweils eine der Dateien laden. Sieh dir in der verlinkten Dokumentation zu der Methode an, welche Daten diese zur\u00fcckgibt. Was wir tun wollen, ist:\n",
                "* alle drei *'NASA bug'*-Dateien in drei separate Datenobjekte `data1` ... `data3` laden und\n",
                "* diese Objekte in [DataFrame](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.html#pandas.DataFrame)s der *pandas*-Library (`df1` ... `df3`) konvertieren. Pandas DataFrame-Objekte sind sehr vielseitige Klassen, weshalb wir unsere Daten in genau dieser Struktur vorhalten und bearbeiten wollen.\n",
                "* Pr\u00fcfen, ob wir die Daten richtig geladen haben.\n",
                "\n",
                "Ersetze die `...` im Code wieder durch die richtigen Eintr\u00e4ge."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "9a68d207-5614-4f1a-aae4-db5b1ccefa45",
            "metadata": {
                "tags": [
                    "Aufgabe"
                ]
            },
            "outputs": [],
            "source": [
                "data1, meta1 = arff.loadarff(...) # NASA bug data 1 laden\n",
                "df1 = pd.DataFrame(data1)         # und die Daten in einen DataFrame konvertieren\n",
                "\n",
                "... # ebenso f\u00fcr bug data 2 und 3.\n",
                "\n",
                "print(df1.shape) # gibt die Dimension des Datensatzes aus, um die Zahl der Instanzen (Eintr\u00e4ge, Zeilen) und der Attribute anzuzeigen.\n",
                "print(...)\n",
                "print(...)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2aab82c0-5d6e-4b18-afb6-29bb4ed8f215",
            "metadata": {
                "tags": [
                    "L\u00f6sung"
                ],
                "jupyter": {
                    "source_hidden": true
                }
            },
            "outputs": [],
            "source": [
                "# Um die L\u00f6sung anzuzeigen, bitte diese Zelle zweimal ausf\u00fchren\n",
                "%load L\u00f6sungen/L\u00f6sung01.py"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6f6066e6-0c2c-44aa-87b4-c41c7d229df3",
            "metadata": {},
            "source": [
                "Wir haben also drei Dateien mit 3619, 3630 und 2774 Eintr\u00e4gen (Zeilen) und 21 Werten pro Eintrag (Attribute/Ergebnisse).\n",
                "\n",
                "Wir wollen aber alle drei Datens\u00e4tze zusammen betrachten und diese daher in einem einzigen Datensatz `df` vereinigen.\n",
                "\n",
                "Passen die Datens\u00e4tze \u00fcberhaupt zusammen? Wenn ja, h\u00e4nge mit dem folgenden Code, der die Methode [concat](https://pandas.pydata.org/docs/reference/api/pandas.concat.html)(...) benutzt, die drei Datens\u00e4tze hintereinander. die Angabe `axis=0` gibt an, dass das Verketten entlang der Achse \"0\" erfolgt (das ist die Index-Achse entlang der Eintr\u00e4ge bzw. Instanzen).</br>\n",
                "Au\u00dferdem haben wir durch die direkt angewendete zweite Methode [reset_index](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.reset_index.html)(...) die Nummerierung der Eintr\u00e4ge von Null beginnend erneuert. Das `drop=True` im Argument ist notwendig, damit nicht eine zus\u00e4tzliche \"index\"-Spalte als Dateneintrag erzeugt wird.\n",
                "\n",
                "F\u00fclle wieder den Code-Teil `...` passend aus (nutze den obigen Link zur Dokumentation) und schau dir die Ausgabe, die das `df` in der zweiten Zeile erzeugt, an. *Stimmt alles?*"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "19280adb-0165-4aff-b3f6-98754e829011",
            "metadata": {
                "tags": [
                    "Aufgabe"
                ]
            },
            "outputs": [],
            "source": [
                "df = pd.concat(..., axis=0).reset_index(drop=True)\n",
                "df"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a0351190-7508-4c75-8abe-e1573d5ef339",
            "metadata": {
                "tags": [
                    "L\u00f6sung"
                ],
                "jupyter": {
                    "source_hidden": true
                }
            },
            "outputs": [],
            "source": [
                "# Um die L\u00f6sung anzuzeigen, bitte diese Zelle zweimal ausf\u00fchren\n",
                "%load L\u00f6sungen/L\u00f6sung02.py"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "18723551-83e9-402c-a59b-47f6dcdf7528",
            "metadata": {},
            "source": [
                "Dir sollte aufgefallen sein, dass in der Ausgabe oben \"10023 rows x **23** columns\" steht, obwohl doch unsere drei urspr\u00fcnglichen Datens\u00e4tze nur **21** Spalten besitzen - das hat uns die Ausgabe durch `print(df1.shape)` wiedergegeben.\n",
                "\n",
                "Grund ist, dass hier *zwei neue* Spalten dazu gekommen sind: **T** und **defect**. Beide Spaltennamen kommen *nur* in `df3` vor aber *nicht* in `df1`, so dass die *concat()*-Methode annimmt, wir h\u00e4tten andere Attribute als zuvor und neue Spalten anlegt.\n",
                "\n",
                "Schaue dir die Spaltennamen von `df1` und `df3` an:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "210fb2eb-54a5-4ce7-adbb-f2cd5f9180cd",
            "metadata": {},
            "outputs": [],
            "source": [
                "df1.columns, df3.columns"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "47e71d3f-874d-4cf3-b54d-4b5be389490d",
            "metadata": {},
            "source": [
                "Hier liegt anscheinend unterschiedliche Schreibweisen vor. Der letzten Datensatz hat statt \"t\" ein \"T\" als Spaltenname (=Name des Attributs bzw. der Codemetrik) und \"defect\" statt \"defects\" als Spaltenname f\u00fcr die Zielgr\u00f6\u00dfe verwendet.\n",
                "\n",
                "Wir m\u00fcssen also die Namen der Spalten *vor* dem Zusammenf\u00fchren korrigieren. Dies tun wir f\u00fcr den letzten Datensatz `df3` mit der Methode [rename](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rename.html)(...). Dem Argument `columns=` \u00fcbergeben wir ein Python-Dictionary - `{alt:neu, ... }` - das den alten auf den neuen korrigierten Namen enth\u00e4lt. Dar Argument `inplace` bewirkt, dass die Korrektur direkt im Datensatz `df3` erfolgt.\n",
                "\n",
                "F\u00fclle den `...`-Teil mit dem Namens-Mapping aus."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "8880e2ce-d8c4-497e-9dcd-3f997f395eaf",
            "metadata": {
                "tags": [
                    "Aufgabe"
                ]
            },
            "outputs": [],
            "source": [
                "df3.rename(columns = ..., inplace=True) # korrigiere abweichende Spaltennamen"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "84abc657-b9ab-415e-91d9-618777378422",
            "metadata": {
                "tags": [
                    "L\u00f6sung"
                ],
                "jupyter": {
                    "source_hidden": true
                }
            },
            "outputs": [],
            "source": [
                "# Um die L\u00f6sung anzuzeigen, bitte diese Zelle zweimal ausf\u00fchren\n",
                "%load L\u00f6sungen/L\u00f6sung03.py"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "4e2cb158-5ab3-4bf1-a03f-2ee8263b9a46",
            "metadata": {},
            "source": [
                "Nun k\u00f6nnen wir nochmal die Verkettung der Datens\u00e4tze durchf\u00fchren:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "bf534667-91b4-4f9b-899e-217512ba11b7",
            "metadata": {},
            "outputs": [],
            "source": [
                "df = pd.concat([df1, df2, df3], axis=0).reset_index(drop=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "05af3e74-fcfc-43e4-80c7-bb40e7d56e7c",
            "metadata": {},
            "source": [
                "Machen wir einen Test, ob die Verkettung - zumindest von den Dimensionen des Datensatzes - funktioniert hat. Der folgende Code sollte `True` ergeben:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f0d27bed-3742-41f4-a7f5-bc765c727097",
            "metadata": {
                "tags": [
                    "Test"
                ]
            },
            "outputs": [],
            "source": [
                "df.shape == (10023, 21)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "8d3d5062-07b3-4a29-99c8-59dbb6eefbbb",
            "metadata": {
                "tags": []
            },
            "source": [
                "### Schritt 2: Datenvorverarbeitung\n",
                "*siehe auch Kapitel 4.1.2 im Buch*"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "01e1ca33-7ffd-472c-a7bb-5e1538d8fd22",
            "metadata": {},
            "source": [
                "Bei der Datenvorverarbeitung k\u00fcmmern wir uns um die Inhalte der Daten, indem wir sie bereinigen, umwandeln, anreichern oder auch Stichproben daraus erheben."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1c99b5f9-8e2f-476a-9403-4c8c47bd78d1",
            "metadata": {
                "tags": []
            },
            "source": [
                "#### Fehlende Werte finden und entfernen"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "75293afc-9c85-4cbe-9a57-5882d80394f4",
            "metadata": {},
            "source": [
                "Bei der Bereinigung suchen wir zum Beispiel nach *falschen* oder *fehlenden* Werten, korrigieren diese, ersetzen sie oder verwerfen sie als fehlerhaft."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f282912c-64ea-40ec-b4c9-6c4f935f3027",
            "metadata": {},
            "source": [
                "In unserem Datensatz `df` suchen wir nach Eintr\u00e4gen mit *NaN*-Werten (also *Not-a-Number*). Das DataFrame-Objekt kennt hier die Methode [isna](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.isna.html#pandas.DataFrame.isna)().\n",
                "Diese gibt einen DataFrame der gleichen Gr\u00f6\u00dfe - jedoch nur mit *True*- oder *False*-Werten - zur\u00fcck. *True* f\u00fcr *NaN*-Werte im urspr\u00fcnglichen DataFrame.\n",
                "\n",
                "Da der Datensatz zu gro\u00df ist (\u00fcber 200.000 Werte), um einen visuellen \u00dcberblick zu bekommen, benutzen wir zus\u00e4tzlich die Methode [sum](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sum.html#pandas.DataFrame.sum)(). Diese z\u00e4hlt alle *True*-Werte in jeder Spalte. Um genau zu sein, interpretiert die Methode *False* als 0 und *True* als 1 und summiert diese Zahlen pro Spalte auf."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3e95d16e-3be7-43bd-820f-385af7169270",
            "metadata": {},
            "outputs": [],
            "source": [
                "df.isna().sum(axis=0)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "228a7326-f840-4903-ab63-40023710b666",
            "metadata": {},
            "source": [
                "Du kannst aus der Ausgabe erkennen, dass die Spalten (Attribute `uniq_Op` bis `branchCount`) jeweils **zwei** Eintr\u00e4ge mit *NaN*-Werten haben.\n",
                "\n",
                "Wir wollen uns nun diese Eintr\u00e4ge selbst genauer ansehen. Wir geben durch die folgende Zeile nur diejenigen Eintr\u00e4ge in `df` zur\u00fcck, die mindestens einen *NaN*-Wert enthalten:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7dd53e8f-f0c7-41e4-aa94-ae145af70f65",
            "metadata": {},
            "outputs": [],
            "source": [
                "df[df.isna().sum(axis=1)>0]"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d3d2c224-9ba6-42ac-b155-e0ff74bd06c3",
            "metadata": {
                "tags": []
            },
            "source": [
                "Wer den obigen Code genauer verstehen m\u00f6chte, kann die folgenden Zellen (...) durch Anklicken aufdecken."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f8a03f41-4244-42c3-b8c5-1191e8c2c044",
            "metadata": {
                "jupyter": {},
                "tags": []
            },
            "source": [
                "Wir identifizieren wieder die fehlenden (*NaN*) Werte. Wir bilden die Summen \u00fcber die Zeilen (axis=1). Diese Summen vergleichen wir mit Null (`>0`) und erhalten so eine Liste, die ein *True* enth\u00e4lt, wenn mindestens ein Wert der Zeile ein *NaN* ist. Benutzen wir diese Liste als Index in den DataFrame, bekommen wir nur diejenigen Zeilen des Datensatzes zur\u00fcck, deren Index *True* ist."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "bba76ebd-9e4b-48e9-82d4-547640fae662",
            "metadata": {
                "jupyter": {},
                "tags": []
            },
            "outputs": [],
            "source": [
                "values_with_na = df.isna()                   # Gibt einen DataFrame - so gro\u00df wie `df` - zur\u00fcck, der nur an den Stellen ein \"True\" enth\u00e4lt,\n",
                "                                             # die in `df` einen \"NaN\"-Wert haben. Alle anderen Eintr\u00e4ge sind \"False\".\n",
                "num_of_na      = values_with_na.sum(axis=1)  # sum() z\u00e4hlt f\u00fcr jeden Eintrag alle \"True\"-Werte entlang der Achse \"1\" - also \u00fcber alle Spalten - und gibt deren Anzahl f\u00fcr jeden Eintrag zur\u00fcck\n",
                "entry_has_na   = num_of_na>0                 # Der Vergleich \">0\" gibt ein \"True\" f\u00fcr jeden Eintrag zur\u00fcck, der gr\u00f6\u00dfer als 0 ist (also in df mindestens einen \"NaN\"-Wert enth\u00e4lt)\n",
                "df[entry_has_na]                             # gibt diejenigen Eintr\u00e4ge aus `df` zur\u00fcck, die in `entry_has_na` ein \"True\" enthalten."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1938f1fb-c648-4165-a0b1-f81dcf59ec6f",
            "metadata": {},
            "source": [
                "Um diese beiden Eintr\u00e4ge aus dem Datensatz zu entfernen, bedienen wir uns der vorgefertigten Methode [dropna](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.dropna.html#pandas.DataFrame.dropna)(). Diese entfernt alle Eintr\u00e4ge bei denen mindestens ein *NaN*-Wert - durch das Argument `how='any'` festgelegt - vorliegt:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "489f5558-2110-4bd8-9035-19a3188473f6",
            "metadata": {},
            "outputs": [],
            "source": [
                "df.dropna(axis=0, how='any', inplace=True)\n",
                "df[2142:2246]"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a3c17d7f-0e41-4d70-b2ed-2515d21f5bcf",
            "metadata": {},
            "source": [
                "Aus dem ausgegebenen Teil des Datensatzes erkennst du, dass die beiden Eintr\u00e4ge mit den Indizes **2144** und **2245** entfernt wurden."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5236cbfb-4548-4eac-8980-1b1fa144c4d1",
            "metadata": {
                "tags": []
            },
            "source": [
                "#### Auf Duplikate pr\u00fcfen und diese entfernen"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d497634c-af3a-4356-9bf9-32700dab4cfb",
            "metadata": {},
            "source": [
                "Ebenfalls Teil der Bereinigung ist, Duplikate aus den Datens\u00e4tzen zu entfernen. Der *pandas*-DataFrame besitzt auch hierf\u00fcr eine zugeschnittene Methode: [drop_suplicates](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html#pandas.DataFrame.drop_duplicates)().\n",
                "\n",
                "Bevor wir diese anwenden, interessiert uns aber wie viele Duplikate es aber \u00fcberhaupt im Datensatz gibt. Diese gibt uns die Methode [duplicated](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.duplicated.html#pandas.DataFrame.duplicated)() als Index-Vektor zur\u00fcck. [value_counts]()() z\u00e4hlt - wie vorher bei den *NaN*-Werten - die nur einmal vorkommenden Eintr\u00e4ge (*False*) und die Duplikate (*True*):"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "75da7e94-aa73-4cbe-9f40-38dae5a913c6",
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "df.duplicated().value_counts()    # df.duplicated() gibt einen Vektor zur\u00fcck, der 'True' f\u00fcr alle erneut vorkommenden _exakten_ Werte-Kombinationen anzeigt."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0659718d-b9da-436b-8007-73af7a1bc983",
            "metadata": {},
            "outputs": [],
            "source": [
                "df.drop_duplicates(inplace=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "52a42721-3ad4-4456-869a-89f744b5cd8a",
            "metadata": {},
            "source": [
                "Der resultierende Datensatz sollte nun nur noch 8927 einmalig vorkommende Eintr\u00e4ge enthalten, was wir gleich testen (das Ergebnis sollte `True` sein):"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f00035f7-98d0-4294-9377-64c3f69b43e7",
            "metadata": {
                "tags": [
                    "Test"
                ]
            },
            "outputs": [],
            "source": [
                "df.shape == (8927, 21)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "39593eaa-377f-43fd-ad75-ceb50538046f",
            "metadata": {},
            "source": [
                "#### Transformation"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "abd4d574-0776-400c-a58b-470285113dee",
            "metadata": {},
            "source": [
                "F\u00fcr einige Algorithmen ist es vorteilhaft mit numerischen Eingabe- und Ausgabewerten zu arbeiten. Wir haben als *defects*-Spalte **kategorische** Werte, die als Zeichenketten vorliegen und die wir in **Zahlen** transformieren. Ein `'false'` soll zu einer `0` werden und ein `'true'` zu einer `1`. Da wir nur in der letzten Spalte Zeichenketten haben, k\u00f6nnen wir gefahrlos die Methode [replace](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.replace.html#pandas.DataFrame.replace)() f\u00fcr unseren Datensatz benutzen. Die ersetzt *alle* Werte, die auf das Argument `to_replace=` passen.\n",
                "\n",
                "Gib f\u00fcr das Argument `to_replace=` ein Dictionary an, das - \u00e4hnlich zur oben verwendeten Methode rename() - alte und neue Werte angibt. Ersetze die Werte direkt im Datensatz (inplace)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f1b6ca83-2078-49c0-a860-ed32d13d1a05",
            "metadata": {
                "tags": [
                    "Aufgabe"
                ]
            },
            "outputs": [],
            "source": [
                "df.replace(to_replace=...,  inplace=...)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6168a1c7-083a-4b92-bba9-4aecb1e50946",
            "metadata": {
                "tags": [
                    "L\u00f6sung"
                ],
                "jupyter": {
                    "source_hidden": true
                }
            },
            "outputs": [],
            "source": [
                "# Um die L\u00f6sung anzuzeigen, bitte diese Zelle zweimal ausf\u00fchren\n",
                "%load L\u00f6sungen/L\u00f6sung04.py"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6e2efdd0-e9e0-40e8-b67a-dd5d82b01850",
            "metadata": {},
            "source": [
                "Sehen wir uns das Ergebnis an, sollte die letzte Spalte **defects** nur noch `0` und `1` Werte enthalten."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ae691ef4-1820-4195-a2d5-5726f8d41542",
            "metadata": {},
            "outputs": [],
            "source": [
                "df"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d2596014-09d0-4292-912d-1b76366d68cc",
            "metadata": {
                "tags": []
            },
            "source": [
                "### Schritt 3: Merkmalsermittlung\n",
                "*siehe auch Kapitel 4.1.3 im Buch.*"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2c474ae0-e0cb-464e-8e14-764b47d189f6",
            "metadata": {},
            "source": [
                "#### Eingabe- und Ausgabewerte aufteilen"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "60d6a56a-6ecd-4cf0-a172-da00c9e6714f",
            "metadata": {},
            "source": [
                "Zun\u00e4chst teilen wir unseren Datensatz in **Eingabe-** (X) und **Ausgabe**werte (y) auf. **X** erstellen wir durch das Entfernen der Spalte *defects*, das wir mit der Methode [drop](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop.html#pandas.DataFrame.drop)() durchf\u00fchren, und in **y** speichern wir direkt als Kopie die letzte Spalte:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "288a5bb2-7377-4d42-96a8-76d60e05e136",
            "metadata": {
                "tags": [
                    "Aufgabe"
                ]
            },
            "outputs": [],
            "source": [
                "X = df.drop(columns=...)  # Speichert einen DataFrame, aus dem die Spalte (...) mit den Ausgabewerten entfernt wurde in X\n",
                "y = df[...]               # Speichert die Spalte (...) mit den Ausgabewereten in y"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fb85fd05-70fb-465b-89c5-3c0d6e31d213",
            "metadata": {
                "tags": [
                    "L\u00f6sung"
                ],
                "jupyter": {
                    "source_hidden": true
                }
            },
            "outputs": [],
            "source": [
                "# Um die L\u00f6sung anzuzeigen, bitte diese Zelle zweimal ausf\u00fchren\n",
                "%load L\u00f6sungen/L\u00f6sung05.py"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "cc9e269d-874f-442f-8917-26e0ccf12cfe",
            "metadata": {},
            "source": [
                "Die resultierenden Daten pr\u00fcfen wir wieder auf ihre Gr\u00f6\u00dfe: Hier sollte `(True, True)` zur\u00fcckgegeben werden."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "359d4b3e-702a-4c6b-b935-1a62bcb8bfa7",
            "metadata": {
                "tags": [
                    "Test"
                ]
            },
            "outputs": [],
            "source": [
                "X.shape == (8927, 20), y.shape == (8927,)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "52b9bbf4-c3d2-4f29-af4e-360bc8f7ccb3",
            "metadata": {},
            "source": [
                "#### Merkmale ausw\u00e4hlen"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "dbafac88-35f4-4817-b3c3-f164a9e24e65",
            "metadata": {},
            "source": [
                "Die in unserem Datensatz enthaltenen Attributen sind m\u00f6glicherweise nicht alle von gleich gro\u00dfer Bedeutung, wenn es darum geht, eine Fehlervorhersage f\u00fcr ein Softwaremodul zu treffen. Doch welche der Attribute eignen sich als Merkmale f\u00fcr das Training, und welche k\u00f6nnen (oder sollten) entfernt werden?\n",
                "\n",
                "Wichtig ist, insbesondere diejenigen *Merkmale zu entfernen, die irrelevant f\u00fcr die Problemstellung sind* (z.B. eine Spalte mit einer *laufenden Nummer*, oder der *Dateiname* eines Softwaremoduls). Da wir gl\u00fccklicherweise keine solchen Spalten in unserem Datensatz haben, brauchen wir uns darum nicht zu k\u00fcmmern."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5743bc6e-ff33-4e35-8444-7e6db2e3d1c0",
            "metadata": {},
            "source": [
                "Doch wie relevant sind dann die verbleibenden Merkmale?\n",
                "\n",
                "Mit einer **Korrelation** kann man zwischen zwei Attributen oder Eingabe-/Ausgabewerten numerisch ermitteln, ob und wie stark deren Wert\u00e4nderungen miteinander in Verbindung (also in Korrelation) stehen.\n",
                "\n",
                "Wir sehen uns dies zun\u00e4chst **zwischen allen Eingabewerten** an und *korrelieren* mit der Methode [corr](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corr.html#pandas.DataFrame.corr)() alle 20 Eingabewerte untereinander, was eine Matrix de Dimension 20x20 ergibt. Diese stellen wir mit der *seaborn*-Funktion [heatmap](https://seaborn.pydata.org/generated/seaborn.heatmap.html)() als farbige Grafik dar.\n",
                "\n",
                "In der Grafik sehen wir, dass auf der Diagonalen der Matrix die Korrelationswerte alle bei `1` liegen. Das sollte uns nicht verwundern, denn genau hier werden die Eingabewerte jeweils mit sich selbst korreliert!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f6062a67-b280-4c14-a60d-c76246cc9989",
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=(12,8), dpi=80)    # Wir geben die Gr\u00f6\u00dfe der Grafik vor\n",
                "sns.heatmap(X.corr(), annot=True, cmap=plt.cm.Reds);"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "f4e37d05-faa9-4b31-ad01-58d57af68a42",
            "metadata": {},
            "source": [
                "Wir sehen au\u00dferdem den Eingabewert \"l\" herausstechen, denn hier sind alle Korrelationen mit den jeweils anderen Werten *negativ*. Dies bedeutet aber nur, dass wenn \"l\" gr\u00f6\u00dfer wird, h\u00e4ufig die anderen Werte kleiner werden. Wir haben also eine *negative Korrelation*."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "32854131-4779-4990-8a32-12278f277d3b",
            "metadata": {},
            "source": [
                "Wir interessieren uns jedoch f\u00fcr die **Korrelation** zwischen **Eingabe-** und **Ausgabe**werten, wof\u00fcr du die Methode [corrwith](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.corrwith.html#pandas.DataFrame.corrwith)(...) verwenden sollst.\n",
                "\n",
                "**Aufgabe:** berechne die Korrelation zwischen X und y, so dass du eine Tabelle mit 20 Eingabegr\u00f6\u00dfen und ihren jeweiligen Korrelationswerten erh\u00e4ltst. Extrahiere aus dieser die *sieben gr\u00f6\u00dften* Eintr\u00e4ge.</br>\n",
                "*Hinweis:* Benutze hierbei auch die Methoden [abs](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.abs.html#pandas.DataFrame.abs)(), [sort_values](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.sort_values.html#pandas.DataFrame.sort_values)(\n",
                "...) und verwende [iloc](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.iloc.html#pandas.DataFrame.iloc)[...], um die 7 gr\u00f6\u00dften Ergebniszeilen auszuw\u00e4hlen."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3d2278f1-9188-4493-9af3-66b729c54ae2",
            "metadata": {
                "tags": [
                    "Aufgabe"
                ]
            },
            "outputs": [],
            "source": [
                "table = X.corrwith(...)..."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f5bef7d8-4769-4de6-9371-8c0bf1a544c4",
            "metadata": {
                "tags": [
                    "L\u00f6sung"
                ],
                "jupyter": {
                    "source_hidden": true
                }
            },
            "outputs": [],
            "source": [
                "# Um die L\u00f6sung anzuzeigen, bitte diese Zelle zweimal ausf\u00fchren\n",
                "%load L\u00f6sungen/L\u00f6sung06.py"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "70747f04-9019-4107-9b9c-493538166119",
            "metadata": {},
            "source": [
                "Von dieser Tabelle verwenden wir nur die linke *Index*-Spalte (mit den Namen der Attribute), welche wir durch das DataFrame-Attribut [.index](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.index.html#pandas.DataFrame.index) erhalten.</br>\n",
                "Die Index-Liste benutzen wir dann, um die entsprechenden Spalten (Merkmale) aus den Eingabewerten **X** zu extrahieren. Dazu nutzen wir die Methode [filter](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.filter.html)().\n",
                "\n",
                "Ersetze wieder die `...` durch die Index-Liste der vorhin erzeugten Tabelle `table`:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e61e3537-af45-4803-a520-f7defad92211",
            "metadata": {
                "tags": [
                    "Aufgabe"
                ]
            },
            "outputs": [],
            "source": [
                "Xf = X.filter(...)\n",
                "Xf"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "2d22c8a5-e7c6-4478-ab8e-42f2816d322f",
            "metadata": {
                "tags": [
                    "L\u00f6sung"
                ],
                "jupyter": {
                    "source_hidden": true
                }
            },
            "outputs": [],
            "source": [
                "# Um die L\u00f6sung anzuzeigen, bitte diese Zelle zweimal ausf\u00fchren\n",
                "%load L\u00f6sungen/L\u00f6sung07.py"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "80366e2a-c901-4988-bf85-c2bfab460e2d",
            "metadata": {},
            "source": [
                "**Hilfestellung:** Hast du bis hierher Probleme gehabt, die Tabelle `table` zu erzeugen, deren Index als Liste darzustellen, oder den Filter auf den Eingabedatensatz X anzuwenden? In der folgenden Zelle (...) findest du eine schnelle L\u00f6sung, mit der du trotzdem die nun folgende Aufgabe 4 vollst\u00e4ndig bearbeiten kannst."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f15d53f1-10c4-4152-b777-407eda781159",
            "metadata": {
                "jupyter": {},
                "tags": []
            },
            "outputs": [],
            "source": [
                "Xf = X.filter(items=['uniq_Opnd', 'loc', 'i', 'n', 'total_Opnd', 'total_Op', 'lOCode'])\n",
                "Xf"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c08b13b2-6fa0-4853-abe4-a076706fae4e",
            "metadata": {
                "toc-hr-collapsed": true
            },
            "source": [
                "## Aufgabe 4: Aufteilen der Daten und Modellgenerierung"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "12efb1c9-e383-462f-9223-2d1830c49e3b",
            "metadata": {},
            "source": [
                "### Einen Entscheidungsbaum trainieren (Test-Split)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "b3eff318-4717-4ea3-8841-f610b81a29c6",
            "metadata": {},
            "source": [
                "Als n\u00e4chstes f\u00fchren wir die folgenden Schritte aus:\n",
                "1. Aufteilen der Daten in Trainings- und Validierungsdaten (Die Nutzung der reduzierten Merkmale in `Xf` und die Abtrennung von Testdaten lassen wir zur Vereinfachung au\u00dfen vor.)\n",
                "2. Einstellen der Modell-Hyperparameter\n",
                "3. Trainieren des Modells mit den Trainingsdaten\n",
                "4. Evaluieren des Modells mit den Validierungsdaten\n",
                "\n",
                "**Aufgabe:** Sieh dir das Ergebnis an und \u00fcberlege dir, ob dein trainiertes Modell gut genug ist!\n",
                "* Welches Problem k\u00f6nnte es geben?\n",
                "* Woran liegt es?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "05d656f5-7f13-4377-93b8-85b7e2c123fb",
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.model_selection import train_test_split   # zum Aufteilen der Trainings- und Testdaten\n",
                "from sklearn                 import tree\n",
                "\n",
                "# 1. Trainings- und Testdaten aufteilen - hier verwenden wir noch ALLE Merkmale!\n",
                "X_train, X_val, y_train, y_val = train_test_split( X, y, test_size=0.1, random_state=4 )\n",
                "\n",
                "# 2. Einen Entscheidungsbaum mit maximaler Tiefe ... erzeugen\n",
                "# 3. und das Modell per '.fit()'-Methode mit den Trainigsdaten trainieren\n",
                "model_dtree = tree.DecisionTreeClassifier(max_depth=15, random_state=16)\n",
                "model_dtree.fit(X_train, y_train)\n",
                "\n",
                "# 4. Die Genauigkeit \u00fcber alle Ergebnisklassen ermitteln: \"Wieviel Prozent aller Ergebnisse waren richtig?\"\n",
                "print('Tiefe des Entscheidungsbaums: {0}'.format(model_dtree.get_depth()))\n",
                "print('Die Genauigkeit auf den Trainingsdaten    liegt bei {0:3.2f}%'.format(model_dtree.score(X_train, y_train)*100))\n",
                "print('Die Genauigkeit auf den Validierungsdaten liegt bei {0:3.2f}%'.format(model_dtree.score(X_val  , y_val  )*100))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "00306267-13ed-4cf8-b14b-d29ff20cc2e4",
            "metadata": {
                "tags": [
                    "Aufgabe"
                ]
            },
            "source": [
                "Zur Erkl\u00e4rung/L\u00f6sung die folgende Zelle (...) anklicken:"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6fd5a1b6-3fcb-43b7-a6b3-2e4519fa7f9b",
            "metadata": {
                "tags": [
                    "L\u00f6sung"
                ],
                "jupyter": {
                    "source_hidden": true
                }
            },
            "source": [
                "**L\u00f6sung:** Die Genauigkeit liegt mit fast 92% nach dem Training sehr hoch und suggeriert ein gutes Modell.\n",
                "\n",
                "Aber die Genauigkeit mit den Validierungsdaten ist mit 71.4% deutlich geringer. Hier haben wir es vermutlich mit einem *Overfit* zu tun. Sehen wir uns den 2. Schritt (im Code oben) an. Siehst du, dass die maximale Tiefe des Entscheidungsbaums auf 15 eingestellt wurde. Unser Modell scheint also *\"zu gro\u00df/komplex\"* f\u00fcr die Aufgabe gew\u00e4hlt."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5b54c08c-60a2-4903-80f0-8fd18c3e4545",
            "metadata": {
                "tags": [
                    "Aufgabe"
                ]
            },
            "source": [
                "**Folgeaufgabe:** Reduziere *im obigen Code* sukzessive die maximal erlaubte Tiefe des Modells, bis Trainings- und Validierungsgenauigkeit \u00e4hnlich gro\u00df sind. Ist jetzt unser Modell gut?"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "9fb7fdff-cc1c-4ff0-a6dd-d7d7a83b73e6",
            "metadata": {
                "tags": []
            },
            "source": [
                "F\u00fcr eine Erkl\u00e4rung/L\u00f6sung die folgenden Zellen (...) anklicken:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4aeee784-05b8-4760-9698-1ebb352c51f4",
            "metadata": {
                "tags": [
                    "L\u00f6sung"
                ],
                "jupyter": {
                    "source_hidden": true
                }
            },
            "outputs": [],
            "source": [
                "# Um die L\u00f6sung anzuzeigen, bitte diese Zelle zweimal ausf\u00fchren\n",
                "%load L\u00f6sungen/L\u00f6sung08.py"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "7c5b5f9a-9cee-4a63-ad18-fa021d5c77a2",
            "metadata": {
                "tags": [
                    "L\u00f6sung"
                ],
                "jupyter": {
                    "source_hidden": true
                }
            },
            "source": [
                "**L\u00f6sung:** Die mit \u00fcber 77.60% scheinbar immer noch gro\u00dfe Genauigkeit t\u00e4uscht: Wir pr\u00fcfen zwar mit der Genauigkeit den Anteil aller richtigen Vorhersagen. Bei stark unausgewogenen Anteilen der Ergebnisklassen (*true* und *false*) ist die Genauigkeit aber keine geeignete Metrik - siehe auch [\u00dcbung Kapitel 5.4: Evaluierung](../Kap05.4_Evaluierung/%C3%9Cbung_Evaluierung.ipynb)\n",
                "\n",
                "Warum ist das so?"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "38be566a-8f4d-49ed-939c-11c32d60edbd",
            "metadata": {},
            "source": [
                "Sehen wir uns die Statistik des gesamten Datensatzes an:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a6dd3bd3-f7a8-4469-853d-2aa40d130e8e",
            "metadata": {},
            "outputs": [],
            "source": [
                "y.value_counts()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ca1389f8-fa94-4cab-8336-58f03bc0f7a1",
            "metadata": {},
            "source": [
                "Wir sehen, dass 6931 Eintr\u00e4ge einen erwarteten Ausgabewert `0` (*false*) haben, aber nur 1996 einen Ausgabewert `1` (*true*). Das bedeutet, dass etwa 77.6% (6931/(6931+1996)) aller Ausgabewerte `0` sind.\n",
                "\n",
                "Ein \"Klassifikator\", der ungeachtet der Eingabewerte konstant `0` als Ausgabe liefert, w\u00fcrde in allen 6931 \"0\"-F\u00e4llen richtig liegen, und in allen anderen falsch und h\u00e4tte damit eine Genauigkeit von 77.6%!\n",
                "\n",
                "Einen solchen Klassifikator kennt auch die *scikit-learn* Bibliothek, den `DummyClassifier`:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "f669fcaa-8249-449a-82da-fde50b554e14",
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "from sklearn import dummy\n",
                "# 1. Trainings- und Testdaten sind schon aufgeteilt (s.o.)\n",
                "# 2. Einen DummyClassifier erzeugen, der konstant die h\u00e4ufigste in y_train vorkommende Klasse zur\u00fcckgibt\n",
                "# 3. und das Modell per '.fit()'-Methode mit den Trainigsdaten \"trainieren\"\n",
                "model_dummy = dummy.DummyClassifier(strategy='most_frequent')\n",
                "model_dummy.fit(X_train, y_train)\n",
                "\n",
                "# 4. Die Genauigkeit \u00fcber alle Ergebnisklassen ermitteln: \"Wieviel Prozent aller Ergebnisse waren richtig?\"\n",
                "print('Die Genauigkeit auf den Trainingsdaten    liegt bei {0:3.2f}%'.format(model_dummy.score(X_train, y_train)*100))\n",
                "print('Die Genauigkeit auf den Validierungsdaten liegt bei {0:3.2f}%'.format(model_dummy.score(X_val  , y_val  )*100))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "17721ed6-f190-4482-a76e-d46cb3231265",
            "metadata": {},
            "source": [
                "### Einen Entscheidungsbaum trainieren (10-fach Kreuzvalidierung)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "1506e734-62db-4744-827b-ad4d3d5e7525",
            "metadata": {},
            "source": [
                "Wir entscheiden uns nun daf\u00fcr, nicht nur die Genauigkeit, sondern auch die **Pr\u00e4zision** und die **Sensitivit\u00e4t** zu evaluieren. Diese ermitteln wir zudem mit der ***k*-fachen Kreuzvalidierung** (siehe auch [\u00dcbung Kapitel 4.2: Datens\u00e4tze aufteilen (Abschnitt: Die k-fache Kreuzvalidierung kurz erkl\u00e4rt)](../Kap04.2_Datens%C3%A4tze_aufteilen/%C3%9Cbung_Datens%C3%A4tze_aufteilen.ipynb).\n",
                "\n",
                "Der folgende Code definiert eine **neue Funktion** `TrainKFold(...)`, die wir im Anschluss benutzen werden, um\n",
                "* die Eingabe- und Ausgabedaten in *folds* aufzuteilen, mit diesen\n",
                "* mehrfach das \u00fcbergebene Modell zu trainieren,\n",
                "* mit den tats\u00e4chlichen und vorhergesagten Ausgaben des Modells eine Konfusionsmatrix zu erstellen und\n",
                "* daraus zum Schluss die resultierende Genauigkeit, Pr\u00e4zision und Sensitivit\u00e4t zu berechnen."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cf465e4a-741e-489d-9da7-99f8b8bf0d11",
            "metadata": {},
            "outputs": [],
            "source": [
                "import matplotlib.pyplot as plt\n",
                "from   sklearn.model_selection    import KFold\n",
                "from   sklearn.metrics            import confusion_matrix, ConfusionMatrixDisplay\n",
                "from   sklearn.utils.class_weight import compute_sample_weight # die Methode verwenden wir erst zum Ende der \u00dcbung\n",
                "\n",
                "# TrainKFold(k, model, X, y, class_weight=None)\n",
                "#   Implementiert das Training des Modells 'model' mit einer 'k'-fachen Kreuzvalidierung\n",
                "#   mit den Eingabewerten 'X' und Ausgabewerten 'y'\n",
                "#   k     - Anzahl der folds f\u00fcr die Kreuzvalidierung\n",
                "#   model - Klassifikations-Modell\n",
                "#   X     - Eingabedaten\n",
                "#   y     - Ausgabedaten\n",
                "#   class_weight - \"balanced\" oder None\n",
                "#                  Gewichtungs-Strategie bei unausgewogenen Ausgangsdaten\n",
                "def TrainKFold(k, model, X, y, class_weight=None):\n",
                "    # Mit KFold eine k-fache Kreuzvalidierung definieren\n",
                "    folds = KFold(n_splits=k, shuffle=True, random_state=4)\n",
                "\n",
                "    # Konfusionsmatrix \n",
                "    cm_all = [[0,0],[0,0]]\n",
                "    # \u00dcber alle Split-Kombinationen der Eingaben (X) und Ausgaben (y) iterieren und jeweils:\n",
                "    for (i_train, i_val) in folds.split(X):\n",
                "        # per '.fit()'-Methode mit den Trainigsdaten trainieren. Achtung: i_train sind nur die Indizes, nicht die Daten\n",
                "        if class_weight == None:\n",
                "            model.fit(X.iloc[i_train], y.iloc[i_train])\n",
                "        else:\n",
                "            y_weights = compute_sample_weight(class_weight=class_weight, y=y.iloc[i_train])\n",
                "            model.fit(X.iloc[i_train], y.iloc[i_train], y_weights)\n",
                "        \n",
                "        y_true = y.iloc[i_val].values\n",
                "        y_pred = model.predict(X.iloc[i_val])\n",
                "        \n",
                "        cm = confusion_matrix(y_true, y_pred)\n",
                "        # Confusion-Matrix: cm[actual,prediction]\n",
                "        #  actual\n",
                "        #    0    [ 0,0 ]=TN  [ 0,1 ]=FP\n",
                "        #    1    [ 1,0 ]=FN  [ 1,1 ]=TP\n",
                "        #            0           1      <== prediction\n",
                "        \n",
                "        accuracy  = (cm[1,1]+cm[0,0])/cm.sum()*100\n",
                "        #precision= cm[1,1]/cm[:,1].sum()*100\n",
                "        #recall   = cm[1,1]/cm[1,:].sum()*100\n",
                "        print(f\" - Modellgenauigkeit auf den fold-Validierungsdaten liegt bei {accuracy:03.2f}%\")\n",
                "\n",
                "        cm_all  += cm\n",
                "\n",
                "    cm = cm_all\n",
                "    ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=['no error', 'defect']).plot(cmap=plt.cm.Blues)\n",
                "    plt.show()\n",
                "    accuracy  = (cm[1,1]+cm[0,0])/cm.sum()*100\n",
                "    precision = cm[1,1]/cm[:,1].sum()*100\n",
                "    recall    = cm[1,1]/cm[1,:].sum()*100\n",
                "    print(f\"Die mittlere Genauigkeit  aller Modelle liegt bei {accuracy:3.2f}%\")\n",
                "    print(f\"Die mittlere Pr\u00e4zision    aller Modelle liegt bei {precision:3.2f}%\")\n",
                "    print(f\"Die mittlere Sensitivit\u00e4t aller Modelle liegt bei {recall:3.2f}%\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "25b08036-3696-4408-800e-d47248696bc7",
            "metadata": {},
            "source": [
                "*Hinweis:* Der obige Code erzeugt hier noch keine Ausgabe. Er definiert nur die neue Funktion.\n",
                "\n",
                "Nachdem die Funktion nun definiert ist, k\u00f6nnen wir\n",
                "* ein Modell - wieder einen Entscheidungsbaum - mit seinen Modellparametern erstellen, \n",
                "* \u00fcber die neue Funktion *k=10* mal trainieren und validieren,\n",
                "* die \u00fcber alle Trainings akkumulierte Konfusionsmatrix anzeigen und\n",
                "* Genauigkeit, Pr\u00e4zision und Sensitivit\u00e4t anzeigen lassen."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5da773fe-3fc4-40ba-b486-781f2ca35ed3",
            "metadata": {},
            "outputs": [],
            "source": [
                "model_dtree = tree.DecisionTreeClassifier(max_depth=3, random_state=16)\n",
                "TrainKFold(10, model_dtree, X, y)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "616576d3-46ac-4993-aa81-d0d1f77b0e7c",
            "metadata": {},
            "source": [
                "Wenn du nun die Maximale Tiefe des Entscheidungsbaums variierst, stellst du fest, dass die resultierende Genauigkeit sich nicht substanziell steigern l\u00e4sst, jedoch Pr\u00e4zision und Sensitivit\u00e4t sich \u00e4ndern."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "670874f7-7dbb-4011-b544-ca41e36b0426",
            "metadata": {},
            "source": [
                "Wir haben bislang noch nicht verglichen, wie sich eine *Reduktion der Merkmale* (die wir in `Xf` gespeichert haben) auswirkt. Dies sehen wir uns jetzt an und tauschen `X` durch `Xf`:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fc6f0da8-9377-46f2-b9c1-9ac9aa784fbc",
            "metadata": {},
            "outputs": [],
            "source": [
                "model_dtree = tree.DecisionTreeClassifier(max_depth=3, random_state=16)\n",
                "TrainKFold(10, model_dtree, Xf, y) # hier verwenden wir Xf (das im Vergleich zu X nur 7 Merkmale enth\u00e4lt)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e8c35849-3b0b-45dc-bed5-ec371302ac3b",
            "metadata": {},
            "source": [
                "Wir sehen, dass sowohl Pr\u00e4zision wie auch die Sensitivit\u00e4t leicht besser geworden sind."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5e353ad4-8eb2-48d8-b6e5-c4729212d261",
            "metadata": {},
            "source": [
                "## Aufgabe 5: Mehr Aufbereitung der Daten"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2bf08588-bfcf-4886-a79a-e618c88da1cc",
            "metadata": {},
            "source": [
                "Auch, wenn die Pr\u00e4zision etwas besser geworden ist, haben wir vielleicht die Vermutung, dass unsere Trainingsdaten noch ungew\u00f6hnliche oder extreme Eintr\u00e4ge enthalten. \n",
                "Wir versuchen daher festzustellen, ob diese **Ausrei\u00dfer** enthalten und **entfernen** diese.\n",
                "\n",
                "Mit [describe](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html)() k\u00f6nnen wir uns zun\u00e4chst einige statistische Werte berechnen lassen:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e5687e4f-7b01-4947-8daf-28b382c2a0e8",
            "metadata": {},
            "outputs": [],
            "source": [
                "df.describe()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "8bc3d174-45fc-45bd-8168-d90207637809",
            "metadata": {},
            "source": [
                "Die Tabelle zeigt f\u00fcr jedes Merkmal die *Anzahl* (count), den *Mittelwert* (mean) und die *Standardabweichung* (std) der Werte, sowie den *minimalen* (min) und *maximalen* (max) vorkommenden Wert.\n",
                "\n",
                "Die Zeilen *25%*, *50%* und *75%* grenzen die sogenannten *Quartilsbereiche* ab. F\u00fcr das Merkmal **loc** (lines of code), das wir in der ersten Spalte sehen, bedeuten die Zahlen folgendes:\n",
                "* (**count**) Es sind insgesamt `8927` Werte im Datensatz.\n",
                "* (**min**) Der kleinste vorkommende Wert ist `0`.\n",
                "* (**max**) Der gr\u00f6\u00dfte vorkommende ist `3422`.\n",
                "* (**25%**) ein Viertel aller Werte in der Spalte sind kleiner als `14.0` (also zwischen 0 und 14)\n",
                "* (**50%**) die H\u00e4lfte aller Werte ist kleiner als `25.0` (die andere H\u00e4lfte ist gr\u00f6\u00dfer). Dieser Wert wird auch als *Median* bezeichnet\n",
                "* (**75%**) ein Viertel aller Werte ist gr\u00f6\u00dfer als `50.0` (also zwischen 50 und 3442)\n",
                "\n",
                "Der Bereich zwischen 25% und 75% wird *Interquartilsbereich* (IQR = Interquartile-Range) genannt und beinhaltet die H\u00e4lfte aller Werte des Merkmals. Sehen wir uns den mit dem **Bloxplot** eine grafische Darstellung dieses Bereiches an, den wir hier f\u00fcr das Merkmal **i** darstellen:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d7602cfd-4ab2-483a-8a9e-2077a85a400c",
            "metadata": {},
            "outputs": [],
            "source": [
                "plt.figure(figsize=[15,2], dpi=80)   # dies bereitet eine praktikable Darstellung der Grafik vor\n",
                "print(df.describe()['i'])            # wir lassen uns hiermit die Statistik zum merkmal 'i' ausgeben\n",
                "sns.boxplot(data=df, x='i');         # diese Zeile erzeugt den Boxplot - nur f\u00fcr das Merkmal 'i'"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "676c080f-c594-424c-8fcb-9cb4ba94335c",
            "metadata": {},
            "source": [
                "Wenn du oben die ausgegebenen statistischen Werte des Merkmals **i** ansiehst und grob mit dem Boxplot vergleichst, erkennst du, dass die blaue \"Box\" genau den *Interquartilsbereich* ($\\text{IQR}=q_{75}-q_{25}$ = `43.675000 - 17.640000 = 26.035000`) belegt.\n",
                "\n",
                "Die T-f\u00f6rmigen Begrenzungen rechts und links neben der Box werden durch \"anh\u00e4ngen\" eines Vielfachens (meist 1.5-fach) des $\\text{IQR}$s. Diese Grenzen bestimmen dann, ob ein Wert als **Ausrei\u00dfer** eingestuft wird oder nicht. Sie hei\u00dfen daher manchmal auch *outlier fence*.\n",
                "\n",
                "Die obere Grenze ist in diesem Fall bei: $q_{75} + 1.5\\cdot\\text{IQR}$ = `82.7275`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ebb03f35-4f27-45e2-88ca-a00170e7550b",
            "metadata": {},
            "outputs": [],
            "source": [
                "43.675000 + 1.5 * 26.035000"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "4a4e4cd8-da65-4924-b443-bfdf1037a2c2",
            "metadata": {},
            "source": [
                "Wir  wollen diese Formel auf *alle Merkmale* anwenden. Daf\u00fcr definieren wir zwei Funktionen, die die obere Grenze (*upper_fence*) und untere Grenze (*lower_fence*) anhand der Eintr\u00e4ge unserer Statistik-Tabelle (siehe oben) berechnen. Dabei ber\u00fccksichtigen wir, dass die obere Grenze nicht gr\u00f6\u00dfer als der maximale Wert und die untere Grenze nicht kleiner als der minimale Wert des Merkmals werden soll."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "00414a3c-831f-46d8-b98d-3c3806ecf25a",
            "metadata": {},
            "outputs": [],
            "source": [
                "def upper_fence(q):\n",
                "    iqr = q.loc['75%'] - q.loc['25%']\n",
                "    return min( q.loc['75%'] + 1.5*iqr, q.loc['max'])\n",
                "\n",
                "def lower_fence(q):\n",
                "    iqr = q.loc['75%'] - q.loc['25%']\n",
                "    return max( q.loc['25%'] - 1.5*iqr, q.loc['min'] )"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "9617f0f7-7898-433f-9487-ed12cf329766",
            "metadata": {},
            "source": [
                "Diese Funktionen wenden wir nun auf die Statistik-Tabelle `stat` an, um die numerischen Werte der beiden *Ausrei\u00dfergrenzen* (*outlier fences*) f\u00fcr jedes Merkmal zu berechnen. Daf\u00fcr nutzen wir die Methode [apply](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.apply.html)() und lassen uns am Ende die oberen Grenzen ausgeben."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "22dcd56d-b281-413a-92de-912eef2e8020",
            "metadata": {},
            "outputs": [],
            "source": [
                "stat = df.describe()\n",
                "low  = stat.apply(lower_fence)\n",
                "high = stat.apply(upper_fence)\n",
                "\n",
                "high"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5b11904e-b455-4351-89d0-ffa5cfe4751f",
            "metadata": {},
            "source": [
                "Du erkennst beim Eintrag **i** wieder den gleichen, wie oben \"von Hand\" ausgerechneten Wert `82.7275`.\n",
                "\n",
                "Bislang haben wir aber \"nur\" die Grenzen selbst berechnet. Nun m\u00fcssen wir diese auf unseren Datensatz anwenden und f\u00fcr jeden einzelnen Eintrag und f\u00fcr jeden Merkmalswert pr\u00fcfen ob dieser unter der unteren oder \u00fcber der oberen *Ausrei\u00dfergrenze* liegt.\n",
                "\n",
                "Ist auch nur ein einziger Merkmalswert (also ein Wert einer Spalte) in einem Eintrag (also einer Zeile) au\u00dferhalb unserer beiden Grenzen, so wollen wir diesen als *Ausrei\u00dfer* aus den Eingabewerten entfernen. Dazu nutzen wir die Methoden *less-than* [lt()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.lt.html) und *greater-than* [gt()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.gt.html), sowie wieder [any()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.any.html). value_counts() zeigt uns wieder an, wie viele der 8927 Eintr\u00e4ge als *outlier* den Wert *True* bekommen haben."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "1349f2d4-3398-4ca1-afc2-7ec23e7092d4",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Wir pr\u00fcfen die Eingabewerte 'X', ob diese\n",
                "# - kleiner als die untere Grenze '.lt(low)'\n",
                "outlier = X.lt(low).any(axis=1) | X.gt(high).any(axis=1)\n",
                "outlier.value_counts()"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "e21b1a3a-5c4d-4fab-a81a-e972d29555fb",
            "metadata": {},
            "source": [
                "Hier sollten in der Ausgabe 3350 Eintr\u00e4ge mit `True` gez\u00e4hlt worden sein.\n",
                "\n",
                "Von den Eingabewerten, die wir in `X` gespeichert haben, selektieren wir nun die *Nicht*-Outlier und legen diese in `X2` ab. Ebenso m\u00fcssen wir mit den Ausgabewerte `y` verfahren, deren verbleibende Ausgabewerte wir in `y2` ablegen."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d95e8357-dd5d-485d-9774-0d9533b67626",
            "metadata": {},
            "outputs": [],
            "source": [
                "X2 = X[~outlier]\n",
                "y2 = y[~outlier]"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "85852123-3670-4f0d-aaf6-fc944240f38f",
            "metadata": {},
            "source": [
                "Wir pr\u00fcfen gleich dein Ergebnis: Stimmt die Anzahl der, um die Ausrei\u00dfer bereinigten Eingabe- und Ausgabewerte? Die Ausgabe sollte `(True, True)` ergeben:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cf8c0e16-8538-4072-8f91-a02d71e855e3",
            "metadata": {
                "tags": [
                    "Test"
                ]
            },
            "outputs": [],
            "source": [
                "X2.shape == (5577,20), y2.shape == (5577,)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "54c52d7d-151d-4fd6-8971-bb3e587cf38d",
            "metadata": {
                "toc-hr-collapsed": true
            },
            "source": [
                "## Aufgabe 6: Modelle mit den zus\u00e4tzlich aufbereiteten Daten"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "75f6bcac-9956-447a-81b5-6df6cb2dbfdc",
            "metadata": {},
            "source": [
                "### 1. Entscheidungsbaum mit allen Merkmalen"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "63428437-31e7-4a07-adf6-74bf04dea969",
            "metadata": {},
            "source": [
                "Wir verwenden zun\u00e4chst wieder einen Entscheidungsbaum, den wir - so wie zuletzt - mit der maximalen Tiefe 3 trainieren (10-fache Kreuzvalidierung). Nun verwenden wir aber die um die *Ausrei\u00dfer* bereinigten Daten `X2` und `y2`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "c10c888e-862e-48f2-8174-06f698805456",
            "metadata": {},
            "outputs": [],
            "source": [
                "model_dtree = tree.DecisionTreeClassifier(max_depth=3, random_state=16)\n",
                "TrainKFold(10, model_dtree, X2, y2)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "07b47fcc-d4d2-4e31-a753-f54111259bc0",
            "metadata": {},
            "source": [
                "Zum Vergleich lag die Pr\u00e4zision des Trainings mit den Ausrei\u00dfern bei ca. 54%. Allerdings ist die Sensitivit\u00e4t dramatisch abgefallen: nur noch 1.56% aller fehlerhaften Softwaremodule w\u00fcrden jetzt als solche erkannt."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5195ce7f-234c-4c0f-8049-696de2559026",
            "metadata": {},
            "source": [
                "### 2. Entscheidungsbaum mit wenigen Merkmalen\n",
                "Wie sieht das Ergebnis aus, wenn wir statt aller Merkmale wieder nur eine Auswahl treffen (die sieben in der `table` als Index gelisteten Merkmale)?"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "a0e8d148-4996-49f1-81ec-62cfc58b9452",
            "metadata": {},
            "outputs": [],
            "source": [
                "X2f = X2.filter(items=table.index)\n",
                "TrainKFold(10, model_dtree, X2f, y2)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "433964b0-9b7a-4d06-a5b4-76b5ce81798e",
            "metadata": {},
            "source": [
                "Wenn du die letzten beiden Konfusionsmatrizen vergleichst, siehst du, dass *nur zwei* der 13 als fehlerhaft vorhergesagten Softwaremodule nun korrekt als nicht-fehlerhaft klassifiziert worden sind. Bei der sehr kleinen Anzahl an Fehlerprognosen macht dies jedoch eine um etwa 4% h\u00f6here Pr\u00e4zision aus!"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c39834a0-d7c1-439f-91ce-5a1a979ed31c",
            "metadata": {},
            "source": [
                "### 2. Neuronales Netz\n",
                "Wir wollen nun ein f\u00fcr Klassifikationen vorbereitetes \"tiefes\" neuronales Netz (NN, oder Multilayer Perceptron) trainieren. Wir erhoffen uns, dass durch die gr\u00f6\u00dfere Anzahl an Modellparametern die Komplexit\u00e4t der Aufgabe vielleicht besser erfasst wird.\n",
                "\n",
                "Wegen des Risikos eines Overfittings gehen wir aber auch hier bei der Evaluierung mit der 10-fachen Kreuzvalidierung vor. Wir k\u00f6nnen auch direkt die zuvor vorbereitete Funktion `TrainKFold` wiederverwenden.\n",
                "\n",
                "Als Algorithmus verwenden wir den *MLPClassifier* der Scikit-Learn bibliothek: [Multilayer Perceptron Klassifikator](https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html#sklearn.neural_network.MLPClassifier). Etwas [Hintergrundinformation](https://scikit-learn.org/stable/modules/neural_networks_supervised.html) zum \"MLP\" in der *scikit-learn* Bibliothek."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "7b8e84a5-7136-470b-a489-92aad8f1130a",
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn import neural_network as nn\n",
                "\n",
                "model_nn = nn.MLPClassifier(hidden_layer_sizes=(10,8,5),  # <--- hier ist die Neuronenanzahl jeder versteckten Schicht aufgelistet\n",
                "                            activation='relu', \n",
                "                            solver='adam',\n",
                "                            validation_fraction=0.1,\n",
                "                            alpha=0.0001, \n",
                "                            learning_rate='adaptive',     # (constant, invscaling, adaptive)\n",
                "                            learning_rate_init=0.001,\n",
                "                            max_iter=250,\n",
                "                            shuffle=True,\n",
                "                            random_state=4)\n",
                "TrainKFold(10, model_nn, X2, y2)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c7cf9b07-70d4-41a3-8847-12f4818e3ade",
            "metadata": {},
            "source": [
                "Wir sehen hier, dass die *Pr\u00e4zision* nochmal besser geworden ist und sogar bei 65% liegt (die Sensitivit\u00e4t ist nach wie vor extrem klein). Diese scheinbare G\u00fcte in der Pr\u00e4zision kann aber auch t\u00e4uschen, denn, wie beim Entscheidungsbaum zuvor, sind hier nur wenige Daten beteiligt und sprechen nicht f\u00fcr ein verl\u00e4ssliches Ergebnis.\n",
                "\n",
                "Du kannst gerne an der Parametrisierung des NN spielen und so versuchen noch besser zu werden... oder auch schlechter.\n",
                "\n",
                "Auch f\u00fcr das gleiche NN versuchen wir mit einem reduzierten Satz an Merkmalen `X2f` das Training:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e208cb12-7c01-48b0-9c63-320176a26cf3",
            "metadata": {},
            "outputs": [],
            "source": [
                "TrainKFold(10, model_nn, X2f, y2)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2a0c2ed9-f760-43bc-9019-d1dca51b3189",
            "metadata": {},
            "source": [
                "Wenn du die Modell-Hyperparameter nicht ver\u00e4ndert hast, siehst du, dass - anders als beim Entscheidungsbaum zuvor - die Pr\u00e4zision schlechter wurde. Es ist also nicht immer so, dass eine einmal getroffene Auswahl von Merkmalen f\u00fcr *jeden* Algorithmus *gleicherma\u00dfen* eine Verbesserung bedeuten muss!"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a0c9ed10-bcaf-49fa-9310-84417d3f1b20",
            "metadata": {},
            "source": [
                "## Aufgabe 7: Unausgeglichene Daten angleichen (Entscheidungsbaum)\n",
                "Wir haben einen Schritt der Datenvorbereitung bislang unterschlagen: Das Erheben einer repr\u00e4sentativen Stichprobe, auch *sampling* genannt.\n",
                "\n",
                "Beim Training eines Entscheidungsbaumes wirkt dies insbesondere auf die Wichtigkeit von Entscheidungsschwellen. Weil wir in unserem Datensatz vergleichsweise wenig Softwaremodule *mit* Fehlerzust\u00e4nden haben, wird eine Erkennung von diesen - zugunsten einer besseren Genauigkeit - nicht so wichtig genommen.\n",
                "\n",
                "Der Trainingsalgorithmus des `DecisionTreeClassifier` erlaubt es f\u00fcr die Eintr\u00e4ge in den Trainingsdaten mit einem Korrekturfaktor zu gewichten - so als ob die h\u00e4ufig vorkommenden Klassen (in unserem Fall `false`) reduziert und die wenig vorkommenden (`true`) angereicht w\u00e4ren. In der von uns geschriebenen Funktion `TrainKFold` k\u00f6nnen wir dieses Feature mit dem zus\u00e4tzlichen Argument `class_weight=\"balanced\"` einschalten:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e3110c69-7939-441c-a32c-73d973e8ca5c",
            "metadata": {},
            "outputs": [],
            "source": [
                "model_dtree = tree.DecisionTreeClassifier(max_depth=3, random_state=16)\n",
                "TrainKFold(10, model_dtree, X2, y2, class_weight=\"balanced\")  # Modelltraining mit allen Merkmalen\n",
                "TrainKFold(10, model_dtree, X2f, y2, class_weight=\"balanced\") # Modelltraining mit den ausgew\u00e4hlten Merkmalen"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "7e44ea57-cdae-4d43-8d29-d786b3ff9e37",
            "metadata": {},
            "source": [
                "\n",
                "Du siehst, dass hier signifikant mehr *Wahr-Positive* Klassifikation (543) stattfinden als zuvor und insbesondere die Sensitivit\u00e4t nun merklich gestiegen ist."
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}