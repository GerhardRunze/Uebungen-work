{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00a0b48c-830a-4794-8ba2-93957e370fa5",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Übung zu Kapitel 6.1 - Neuronale Netze\n",
    "\n",
    "*Eine Übung zum Buch \"[Basiswissen KI-Testen - Qualität von und mit KI-basierten Systemen](https://dpunkt.de/produkt/basiswissen-ki-testen/)\", ISBN 978-3-86490-947-4*\n",
    "\n",
    "In dieser Übung geht es darum, neuronale Netze besser kennenzulernen. Die Grundlagen zu dieser Aufgabe findest du in Abschnitt 6.1 des Buches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8d497b-2144-4d65-9e87-e8a57d077caf",
   "metadata": {},
   "source": [
    "Wir haben zwei Aufgaben vorbereitet:\n",
    "* Aufgabe 1: Ein Perzeptron trainieren (mit Excel)\n",
    "* Aufgabe 2: Ein neuronales Netz trainieren (mit TensorFlow Playground)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "490555ca-0f9f-4911-83c1-b7a442d53261",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Aufgabe 1 - Ein Perzeptron trainieren\n",
    "Trainiere ein einfaches **Perzeptron**, eine logische **UND-Funktion** mit zwei Eingabewerten zu realisieren. Die Eingabedaten sollen dabei nur die ganzzahligen Werte 0 und 1 sein – ebenso der Ausgabewert.\n",
    "\n",
    "*Etwas Hintergrund zum Perzeptron, künstlichen und biologischen Neuronen - wenn du möchtest - in der ausgeblendeten Zelle ...*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e5da93-700d-4319-95a5-ca558e0b5eb9",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "Lösung"
    ]
   },
   "source": [
    "<img src=\"data/6.1-1_NeuronaleNetze_Perzeptron.png\" alt=\"perceptron\" width=\"600\">\n",
    "\n",
    "In der Abbildung sehen wir eine schematische Darstellung eines künstlichen Neurons, das in ein Netzwerk von künstlichen Neuronen eingebettet ist (links). Hervorgehoben ist der Teil, der als einschichtiges Perzeptron bezeichnet wird. Das Perzeptron ist inspiriert von der Funktionsweise biologischer Neuronen. Ein sehr vereinfachtes biologisches Neuron ist rechts zu sehen. Die verbindende Funktionalität zwischen dem künstlichen und dem biologischen Neuron besteht darin, mehrere Eingangssignale/Eingabewerte (meistens Ausgaben anderer Neuronen) zu einem einzigen Ausgabesignal/Ausgabewert zu verarbeiten. \n",
    "\n",
    "Mit nur einem Perzeptron können mathematische Operationen wie die UND-Funktion realisiert werden, worauf wir uns in dieser Aufgabe genauer konzentrieren werden. Ganze Netzwerke von Perzeptronen, dann sprechen wir von künstlichen neuronalen Netzen, können komplexe mathematische Aufgaben wie in der Bilderkennung oder in der Sprachverarbeitung bewältigen. Bevor wir in Aufgabe 2 ein neuronales Netzwerk anschaulich trainieren, wollen wir in dieser Aufgabe ein Gefühl dafür bekommen, wie ein Perzeptron als kleinste Einheit eines neuronalen Netzes funktioniert."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5992132-6546-45d0-97cf-5ccff8746a2c",
   "metadata": {},
   "source": [
    "Öffne für diese Aufgabe die **Excel-Datei** *\"Übung_Perzeptron.xlsx\"* direkt in Excel und folge den dort beschriebenen Schritten. In der Excel-Datei selbst findest du ausreichend Hilfestellungen, um die Aufgabe zu lösen.\n",
    "\n",
    "Ziel dieser Aufgabe ist es, dass du den Zyklus einer Lernepoche von den Trainingsdaten bis zur Korrektur der Parameter nachstellen kannst und über mehrere Epochen das Perzeptron trainierst, bis es die UND-Funktion erfolgreich gelernt hat."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27e69b0c-486a-4e69-b8ff-b9bcdd9437f6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Lösung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3572c82-1077-4ba1-be32-6c95266b98c3",
   "metadata": {
    "tags": []
   },
   "source": [
    "Das Perzeptron, das die UND-Funktion realisieren soll, erhält zwei Eingabewerte $X_1$ und $X_2$ und soll einen Wert $Y$ ausgeben, der einer logischen UND-Operation entspricht. Da die beiden Eingabewerte jeweils nur 0 oder 1 sein können, gibt es genau vier Datenpunkte in unserem Trainingsdatensatz, wie in der folgenden Abbildung auch grafisch dargestellt ist.\n",
    "\n",
    "![Image](data/6.1-Lösung1-1a.png) ![Image](data/6.1-Lösung1-1b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c75c306-d340-4af4-8cca-0d7ae0fe14b5",
   "metadata": {
    "tags": []
   },
   "source": [
    "Aus diesen Daten beschreiben wir in der Excel-Tabelle, die das Training des Perzeptrons darstellen soll, dessen Ausgabe $Y_{out}$ (entspricht dem Aktivierungswert $\\varphi()$) im jeweiligen Schritt als Excel-Funktion:\n",
    "\n",
    "$V$ = $w_1$ * $X_1$ + $w_2$ * $X_2$ + $b$\n",
    "\n",
    "$Y_{out}$ = WENN($V$>0; 1; 0)\n",
    "\n",
    "![Image](data/6.1-Lösung1-2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b292220-2093-4c27-8e01-5093242e80f0",
   "metadata": {
    "tags": []
   },
   "source": [
    "Außerdem bestimmen wir den **Fehler** $F$ im jeweiligen Schritt, indem wir den Aktivierungswert $Y_{out}$ vom erwarteten Wert $Y$ aus den Trainingsdaten abziehen:\n",
    "\n",
    "$F$ = $Y$ – $Y_{out}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61191da4-a042-4eb2-84e9-d42be25a2f9e",
   "metadata": {
    "tags": []
   },
   "source": [
    "Im allerersten Trainingsschritt verwenden wir für die Gewichte und den Bias beliebige Startwerte. In allen weiteren Schritten verändern wir diese jeweils so, dass wir die im Schritt zuvor als Fehler $F$ beobachtete Abweichung über die Gewichte und den Bias zu kompensieren versuchen:\n",
    "\n",
    "$w_{1,neu}$ = $w_{1,alt}$ + $F$ * $X_{1,alt}$ * *alpha*\n",
    "\n",
    "$w_{2,neu}$ = $w_{2,alt}$ + $F$ * $X_{2,alt}$ * *alpha*\n",
    "\n",
    "War zuvor $Y_{out}$ im Vergleich zu $Y$ zu klein, ist der Fehler $F$ positiv. Ein positives $F$ vergrößert das Gewicht $w_1$ (bzw. $w_2$) und vergrößert damit $Y_{out}$ im nächsten Schritt. Diese Wirkung hängt aber auch von der Anregung durch den jeweiligen Eingang $X_1$ (bzw. $X_2$) ab. Wir multiplizieren daher die Korrektur zusätzlich mit jeweils $X_1$ (bzw. $X_2$). Damit die Sprünge in den Werten für $w_1$ und $w_2$ nicht zu groß werden und der Trainingsalgorithmus zu einer Lösung konvergiert, verringern wir die Größe der Schritte über einen weiteren Faktor *alpha*, der Lernrate. Diese ist oft deutlich kleiner als 1 (siehe Buchabschnitt 6.1) und bestimmt einerseits die Stabilität des Lernalgorithmus (je kleiner, desto besser), aber auch die notwendige Trainingszeit (je kleiner desto länger)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5254c99-5f61-4722-9400-6c1007e4a2f4",
   "metadata": {
    "tags": []
   },
   "source": [
    "Analog zu den Gewichten kompensieren wir die Abweichung gleichzeitig auch über eine Anpassung des Biaswertes:\n",
    "\n",
    "$b_{neu}$ = $b_{alt}$ + $F$ * *alpha*\n",
    "\n",
    "Im Unterschied zu den Gewichten trägt der Biaswert immer zur Ausgabe bei, weshalb wir die Multiplikation mit einem Eingabewert unterlassen."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "854efc00-2b5c-4b59-9f68-2ccbd417554c",
   "metadata": {},
   "source": [
    "## Aufgabe 2 - Ein neuronales Netz trainieren"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c7fa91-0d1a-431d-984c-8b3d6f9e5676",
   "metadata": {},
   "source": [
    "Trainiere ein **neuronales Netz**, die **Exklusiv-Oder-Funktion (XOR)** zu realisieren. Benutze dazu die Onlineplattform [TensorFlow Playground](https://playground.tensorflow.org)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d53408f-b57b-43d9-9c51-061d4e7715ad",
   "metadata": {},
   "source": [
    "Wenn du die Webseite öffnest, siehst du ein Schema eines neuronalen Netzes mit einer Eingabeschicht (dort als FEATURES bezeichnet), versteckten Schichten (HIDDEN LAYER) und einer Ausgabeschicht (OUTPUT). Diese erzeugt nur einen einzigen Ausgabewert, der als zweidimensionale Farbgrafik dargestellt ist. An der Eingabeschicht kann man die dort vorgegebenen Merkmale (FEATURES), die verarbeitet werden sollen, auswählen (siehe Abschnitt 4.1 im Buch).\n",
    "\n",
    "Gehe durch die folgenden Schritte und beantworte dabei auch die gestellten Fragen. Die Icons helfen dir dabei, die richtige Stelle auf der Webseite zu finden."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176a484d-5782-4867-a8f7-5c939ff7a34d",
   "metadata": {},
   "source": [
    "<table style=\"background:#ffffff\">\n",
    "    <tr><td>1. Wähle die Trainings- und Testdaten (DATA) für das Exklusiv-Oder (engl. exclusive or) aus (durch das Icon am Rand dargestellt).</td><td><img src=\"data/6.1-Aufgabe2_Punkt1.png\" width=32/></td></tr>\n",
    "    <tr><td>2. Starte das Training mit dem Play-Button (Run/Pause) oben links.</td><td><img src=\"data/6.1-Aufgabe2_Punkt2.png\" width=24/></td></tr>\n",
    "    <tr><td>3. Wird das neuronale Netz gut genug auf die Daten trainiert?\n",
    "Wenn nicht, versuche die Startwerte für Gewichte und den Bias-Wert mit dem Reset-Button auf andere Zufallswerte zu setzen und starte das Training erneut.</td><td><img src=\"data/6.1-Aufgabe2_Punkt3.png\" width=24/></td></tr>\n",
    "    <tr><td>4. Reduziere nun die Anzahl der versteckten Schichten. Verändere dabei auch die Zahl der Neuronen pro Layer. Wie viele Layer und Neuronen brauchst du mindestens?</td><td><img src=\"data/6.1-Aufgabe2_Punkt4.png\" width=48/></td></tr>\n",
    "    <tr><td>5. Stelle nun den Trainings-Test-Split auf 90:10 ein (engl. ratio of training to test data: 90%) und stelle eine versteckte Schicht mit drei Neuronen ein. Wie gut funktioniert das Training?</td><td><img src=\"data/6.1-Aufgabe2_Punkt5.png\" width=48/></td></tr>\n",
    "    <tr><td>6. Wie verändert sich das Trainingsergebnis, wenn du statt der <em>Tanh</em>-Aktivierungsfunktion (engl. activation) die <em>ReLU</em>-Funktion auswählst?</td><td><img src=\"data/6.1-Aufgabe2_Punkt6.png\" width=64/></td></tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32855776-04ba-4d2f-9a11-2c7f0b0758c2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Lösung"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "452a3d98-70ca-4cb1-9fea-e7f8c9826f20",
   "metadata": {},
   "source": [
    "Die Standardeinstellung von Tensorflow Playground gibt ein Netzwerk mit zwei versteckten Layern vor, das vier bzw. zwei Neuronen pro Layer enthält."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07e0c77a-b814-43db-9624-7a1bd89e648f",
   "metadata": {},
   "source": [
    "*Nach Schritt 2* siehst du, wie der Trainingsalgorithmus startet (der Epochenzähler läuft hoch) und mit den ausgewählten XOR-Trainingsdaten die Parameter der Neuronen anpasst. Als Folge ändern sich die Gewichte der Neuronen (Farbe und Dicke der Linien zwischen den Neuronen) und der Ausgang spiegelt durch die farbliche Kodierung im Bild wider, welcher Ausgabewert bei einer Kombination von Eingabewerten (als Koordinaten im Bild) ausgegeben würde."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "775a9cdd-33b4-47a7-b49b-e6edc24b54da",
   "metadata": {},
   "source": [
    "*Schritt 3:* Je nach Startwert der Modell-Parameter kannst du beobachten, wie sich die erzeugten Lösungen leicht unterscheiden.\n",
    "\n",
    "Die folgenden Grafiken a) bis d) zeigen die Ausgaben von vier trainierten ML-Modellen. Obwohl die Trainingsdaten identisch sind, unterscheiden sich die Lösungen der Modelle, weil wir unterschiedliche Startwerte der Modellparamter gewählt haben. Blaue bzw. dunkelgraue Bereich entsprechen Ausgaben des Modells von +1, orangene bzw. hellgraue Bereiche Ausgaben von -1.\n",
    "\n",
    "a) ![Image](data/6.1-Lösung2-1a.png) &emsp; b) ![Image](data/6.1-Lösung2-1b.png) &emsp; c) ![Image](data/6.1-Lösung2-1c.png) &emsp; d) ![Image](data/6.1-Lösung2-1d.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f72a1da-3eb5-46a9-b441-f5a083d6b802",
   "metadata": {},
   "source": [
    "*Schritt 4:* Entfernst du **alle** versteckten Layer, solltest du beobachten können, dass das Training keine passende Lösung findet. Das liegt daran, dass das einzig verbleibende Neuron der Ausgabeschicht nur eine lineare Kombination der Eingabewerte X1 und X2 (genauso wie bei der UND-Funktion aus Aufgabe 1) ermöglicht. Das Vorzeichen des Ausgabewertes des Perzeptrons ist durch eine gerade Linie in der Grafik bestimmt. \n",
    "\n",
    "Du brauchst **mindestens einen** versteckten Layer. Die Zahl der Neuronen, die du für eine annähernd gute Lösung &ndash; bei sonst unveränderten Einstellungen &ndash; benötigst, ist vier, wenn gute Startwerte vorliegen. Je mehr es sind, desto einfacher wirst du eine akzeptable Lösung finden.\n",
    "\n",
    "*Hidden Layer mit 4 Neuronen und Tanh-Aktivierungsfunktion*</br>\n",
    "![Image](data/6.1-Lösung2-2a.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3982ce1-164e-45b6-8c14-9c7e2d11ea79",
   "metadata": {},
   "source": [
    "*Schritt 5:* Wie zu erwarten, ergibt ein Netzwerk mit drei Neuronen keine befriedigende Lösung\n",
    "\n",
    "*Hidden Layer mit 3 Neuronen und Tanh-Aktivierungsfunktion*</br>\n",
    "![Image](data/6.1-Lösung2-2b.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdc6342a-e5c3-4912-a674-02b3bddbccc3",
   "metadata": {},
   "source": [
    "Schritt 6: Anders sieht es hingegen aus, wenn du die Aktivierungsfunktion *ReLU* verwendest. Diese ist gut geeignet, wenn positive Werte Bedeutung haben, negative hingegen nicht. Bei logischen Operationen wie der XOR-Funktion ist dies von Vorteil. Daher sind selbst mit drei Neuronen sogar noch bessere Ergebnisse erzielbar als bei unseren ersten Versuchen.\n",
    "\n",
    "*Hidden Layer mit 3 Neuronen und ReLU-Aktivierungsfunktion*</br>\n",
    "![Image](data/6.1-Lösung2-2c.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
