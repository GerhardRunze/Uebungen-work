{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "00a0b48c-830a-4794-8ba2-93957e370fa5",
            "metadata": {},
            "source": [
                "# \u00dcbung zu Kapitel 8.6 - Erkl\u00e4rbare KI\n",
                "\n",
                "*Eine \u00dcbung zum Buch \"[Basiswissen KI-Testen - Qualit\u00e4t von und mit KI-basierten Systemen](https://dpunkt.de/produkt/basiswissen-ki-testen/)\", ISBN 978-3-86490-947-4*\n",
                "\n",
                "In dieser \u00dcbung sehen wir uns das Qualit\u00e4tsmerkmal der *Erkl\u00e4rbarkeit* einer KI-Komponente an. Dabei wirst du auch selbst zwei Algorithmen, die bei der Erkl\u00e4rbarkeit von KI h\u00e4ufig verwendet werden (LIME und SHAP), anwenden. Die Grundlagen zur *Transparenz*, *Interpretierbarkeit* und *Erkl\u00e4rbarkeit* findest du in Abschnitt 8.6 des Buches.\n",
                "\n",
                "[<img src=\"https://numpy.org/doc/stable/_static/numpylogo.svg\" alt=\"Numpy\" width=\"80\" height=\"24\">](https://numpy.org/doc/stable/reference/index.html#reference)\n",
                "&emsp; [<img src=\"https://pandas.pydata.org/docs/_static/pandas.svg\" alt=\"pandas\" width=\"80\" height=\"24\">](https://pandas.pydata.org/docs/reference/index.html)\n",
                "&emsp; [<img src=\"https://scikit-learn.org/stable/_static/scikit-learn-logo-small.png\" alt=\"Scikit-learn\" width=\"80\" height=\"24\">](https://scikit-learn.org/stable/modules/classes.html)\n",
                "&emsp; [<img src=\"https://matplotlib.org/_static/logo_light.svg\" alt=\"Matplotlib\" width=\"100\" height=\"24\">](https://matplotlib.org/)\n",
                "\n",
                "\n",
                "Diese \u00dcbung setzt sich aus folgenden Aufgaben zusammen:\n",
                "\n",
                "**Aufgabe 1:**\n",
                "Importiere das in der praktischen \u00dcbung 4.2.1 erstellte Modell eines Entscheidungsbaums, um die Schwertlilien-Art anhand verschiedener Merkmale vorherzusagen. Visualisiere das Ergebnis mit Methoden aus der sklearn-Bibliothek.\n",
                "\n",
                "**Aufgabe 2:**\n",
                "Auch wenn ein Entscheidungsbaum ein von sich aus erkl\u00e4rbares Modell ist, wollen wir die Erkl\u00e4rmethode LIME beispielhaft daran zeigen. Wende auf unser Modell die Erkl\u00e4rmethode LIME an, um die Ausgaben des Modells f\u00fcr einzelne Beispiele zu erl\u00e4utern (https://github.com/marcotcr/lime).\n",
                "\n",
                "**Zusatzaufgabe:**\n",
                "Verwende den SHAP-Ansatz, um das Modell zu erkl\u00e4ren (https://shap.readthedocs.io/en/latest). Wie unterscheidet sich der SHAP-Ansatz vom LIME-Ansatz?\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d7042ad6-998e-40ea-a404-54afed6c2a96",
            "metadata": {},
            "source": [
                "## Aufgabe 1\n",
                "Importiere das in der praktischen \u00dcbung 4.2.1 erstellte Modell eines Entscheidungsbaums, um die Schwertlilien-Art anhand verschiedener Merkmale vorherzusagen. Visualisiere das Ergebnis mit Methoden aus der sklearn-Bibliothek."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "4578e23d-6975-489b-bfeb-e4a2a3effaa4",
            "metadata": {},
            "source": [
                "**Schritt 1:** importiere zuerst das Modell, das du in [\u00dcbung 4.2](../Kap04.2_Datens\u00e4tze_aufteilen/\u00dcbung_Datens\u00e4tze_aufteilen.ipynb) erstellt und abgespeichert hast."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4afe3c6a-2f2e-445c-911d-010318b75a33",
            "metadata": {
                "tags": [
                    "Aufgabe"
                ]
            },
            "outputs": [],
            "source": [
                "import joblib as jl     # wir ben\u00f6tigen die joblib um das Modell zu laden\n",
                "\n",
                "model = jl.load(...)    # gib hier den Pfad zur *pkl*-Datei an, die du in \u00dcbung 4.2 abgespeichert hast.\n",
                "                        # hast du die \u00dcbung nicht bis zum Ende gemacht, kannst du das im Verzeichnis data vorbereitete Modell nehmen\n",
                "model"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fddfaeaa-331f-40bd-8a9e-ed2935361d4c",
            "metadata": {
                "tags": [
                    "L\u00f6sung"
                ],
                "jupyter": {
                    "source_hidden": true
                }
            },
            "outputs": [],
            "source": [
                "# Um die L\u00f6sung anzuzeigen, bitte diese Zelle zweimal ausf\u00fchren\n",
                "%load L\u00f6sungen/L\u00f6sung01.py"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c992e0f3-c27a-446d-b4f5-8c76dc9e621c",
            "metadata": {},
            "source": [
                "Das oben geladene Modell ist ein [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html#sklearn.tree.DecisionTreeClassifier) Objekt. \u00dcber den Link kannst du in der scikit-learn Library mehr dar\u00fcber nachlesen.\n",
                "\n",
                "**Schritt 2:** Wir schauen uns an, was das Modell selbst an *\"Erkl\u00e4rungen\"* zu bieten hat:\n",
                "* Mit `.feature_names_in_` k\u00f6nnen wir uns ansehen, welche Features (Merkmale) f\u00fcr den Entscheidungsbaum beim Trainieren ausgew\u00e4hlt wurden.\n",
                "* Mit `.feature_importances_` k\u00f6nnen wir ansehen, wie wichtig diese Features f\u00fcr die Unterscheidung der Ergebnisklassen sind."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "43094e94-16d9-457b-87d1-ad897a09791a",
            "metadata": {
                "tags": []
            },
            "outputs": [],
            "source": [
                "import pandas as pd     # wir stellen den Output mit Hilfe der Pythonbibliothek pandas dar\n",
                "\n",
                "# Daten in ein Pandas DataFrame umwandeln\n",
                "data = {'Feature Names':       model.feature_names_in_, \n",
                "        'Feature Importances': model.feature_importances_}\n",
                "pd.DataFrame(data)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "2f4b5fe1-4e92-4150-b98a-eebb6a05eba4",
            "metadata": {},
            "source": [
                "In dem Modellbeispiel siehst du, dass die Features (Merkmale) in dem Modell unterschiedliche Wichtigkeit bei der Klassifizierung haben.\n",
                "\n",
                "**Schritt 3:** Um noch mehr Informationen sichtbar und die Details des Entscheidungsbaums deutlich zu machen, kannst du \u00fcber das scikit-learn Objekt *tree* und dessen Methode [plot_tree()](https://scikit-learn.org/stable/modules/generated/sklearn.tree.plot_tree.html#sklearn.tree.plot_tree) den Entscheidungsbaum selbst visualisieren:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "26ea65de-ea36-443e-929d-310edf5ea839",
            "metadata": {},
            "outputs": [],
            "source": [
                "from   sklearn           import tree    # wir verwenden die Klasse tree aus der sklearn-Bibliothek \n",
                "import matplotlib.pyplot as     plt     # wir ben\u00f6tigen matplotlib f\u00fcr grafische Darstellungen\n",
                "\n",
                "plt.figure(figsize=(10,8))\n",
                "vis = tree.plot_tree(model, feature_names = model.feature_names_in_, class_names = [\"0\",\"1\",\"2\"], fontsize = 8, filled = True, rounded=True)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a36ff4bc-7f9c-4efd-bf00-9938a72cd4dc",
            "metadata": {
                "tags": [
                    "Aufgabe"
                ]
            },
            "source": [
                "Schau dir den Entscheidungsbaum und die in den Knoten eingetragenen Werte genauer an (ggf. auch in der Dokumentation zur plot_tree()-Methode). Dazu ein paar **Fragen**:\n",
                "1. Welche Information beinhaltet die erste Zeile der Knoten? Was ist der Unterschied zwischen den Knoten?\n",
                "1. Was bedeutet der Eintrag `class = x`?\n",
                "1. Was bedeuten z.B. `samples = 91` und `values = [0, 47, 44]`?\n",
                "1. Was bedeutet die Farbe des Knoten?\n",
                "\n",
                "*Hinweis:* Der *Gini*-Index oder die *Gini*-Unreinheit misst den Grad der Ausgewogenheit eines Datensatzes. Die *Gini*-Unreinheit, eine Zahl zwischen 0 und 0.5, dient bei der Erstellung von Entscheidungsb\u00e4umen dazu, die Wahrscheinlichkeit anzugeben, dass neue zuf\u00e4llige Daten falsch klassifiziert werden.\n",
                "\n",
                "**L\u00f6sung:** Die *Antworten* zu den Fragen findest du in der n\u00e4chsten Zelle (auf die `...` klicken)."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "34dd1366-2b30-41d0-835c-84342f87ea50",
            "metadata": {
                "tags": [
                    "L\u00f6sung"
                ],
                "jupyter": {
                    "source_hidden": true
                }
            },
            "source": [
                "1. Knoten an denen eine *Entscheidung* getroffen wird, haben in der ersten Zeile das Merkmal mit einer Bedingung stehen (z.B. `petallength <= 2.6`). Trifft die Bedingung zu, wird der linke Zweig gew\u00e4hlt, andernfalls der rechte. Die Knoten, die keine Bedingung in der ersten Zeile angeben, sind die Bl\u00e4tter, die die Schwertlilien-Arten widerspiegeln. \n",
                "1. Der Eintrag `class = x`, dass diese Klasse x - w\u00e4hrend der Entscheidungsbaum (bei der Inferenz) durchlaufen wird, ausgehend von dem bis dahin durchlaufenden Entscheidungsbaum - gerade am wahrscheinlichsten ist.\n",
                "1. Der Eintrag `samples = 91` in einem Knoten bedeutet, dass f\u00fcr 91 Trainingsdaten dieser Knoten durchlaufen wurde. Die Werte `values = [0, 47, 44]` geben dabei an, zu welchen Klassen (0, 1, 2) diese Samples geh\u00f6ren (kein Sample der Klasse 0, 47 Samples der Klasse 1 und 44 Samples der Klasse 2).\n",
                "1. Die *Farbe* des Knotens gibt an, *welche* Klasse am wahrscheinlichsten ist (Klassen: 0=orange, 1=gr\u00fcn, 2=lila). Die *Farbs\u00e4ttigung* zeigt, wie *wahrscheinlich* diese Klasse schon ist."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "4c114c1c-2868-44de-85c7-e26c0f3395c3",
            "metadata": {},
            "source": [
                "## Aufgabe 2\n",
                "Auch wenn ein Entscheidungsbaum ein von sich aus erkl\u00e4rbares Modell ist, wollen wir die Erkl\u00e4rmethode LIME beispielhaft daran zeigen. Wende auf unser Modell die Erkl\u00e4rmethode LIME an, um die Ausgaben des Modells f\u00fcr einzelne Beispiele zu erl\u00e4utern (https://github.com/marcotcr/lime)!\n",
                "\n",
                "Achtung: Du musst Aufgabe 1 zuvor bearbeitet haben."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "48005c20-67ba-4df0-9e39-d2094f235e20",
            "metadata": {},
            "source": [
                "**Schritt 1:** Der LIME-Algorithmus verwendet konkrete Daten, um eine Erkl\u00e4rung f\u00fcr beispielsweise ein konkretes Klassifikationsergebnis zu geben. Daher laden wir wieder den Iris-Datensatz aus der \u00dcbung 4.1:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "fd4e0a2d-d02d-4539-aa69-0f6dae8ee833",
            "metadata": {
                "tags": [
                    "Aufgabe"
                ]
            },
            "outputs": [],
            "source": [
                "import pandas as pd\n",
                "iris = pd.read_csv(...) # Lade die iris-Daten aus der vorangegangenen \u00dcbung 4.1\n",
                "iris                    # und zeige die Daten an"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "6e768859-2205-4d5b-a221-57b07112c8b5",
            "metadata": {
                "tags": [
                    "L\u00f6sung"
                ],
                "jupyter": {
                    "source_hidden": true
                }
            },
            "outputs": [],
            "source": [
                "# Um die L\u00f6sung anzuzeigen, bitte diese Zelle zweimal ausf\u00fchren\n",
                "%load L\u00f6sungen/L\u00f6sung02.py"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "9cd4e24f-9f82-40e9-a20c-3c3f759179f3",
            "metadata": {},
            "source": [
                "**Schritt 2:** Wir m\u00fcssen nun wieder die Iris-Daten in Eingabe- `X` und Ausgabedaten `y` sowie Trainings- `..._train` und Testdaten `..._test` aufteilen."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "cc8e0cc7-8063-49e5-9e30-eae9a40dd196",
            "metadata": {},
            "outputs": [],
            "source": [
                "from sklearn.model_selection import train_test_split   # importiere diese Methode aus der scikit-learn bibliothek\n",
                "\n",
                "# Aufteilen in Eingaben (X) und Ausgaben (y)\n",
                "X = iris.drop(columns='class')     # Entfernt aus dem DataFrame die Spalte mit dem Namen 'class' (den Output)\n",
                "y = iris.filter(items=['class'])   # Filtert nur die Spalte 'class' heraus (also entfernt alle anderen) \n",
                "\n",
                "# Aufteilen in Trainings-, Validierungs- und Testdaten\n",
                "X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.1, random_state=4 )"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c4bec701-b37d-43f0-9aea-c6e56e10d75f",
            "metadata": {},
            "source": [
                "Stimmen die Merkmale des Iris-Datensatzes mit denen aus dem geladenen Modell \u00fcberein? Schau dir die Spalten\u00fcberschriften aus dem vorhergehenden Schritt an und vergleiche sie mit den 'Features' des Modells aus Aufgabe 1.\n",
                "\n",
                "Machen wir einen Test:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "76fef6d1-bc5f-418a-8309-f6c4c38e7550",
            "metadata": {
                "tags": [
                    "Test"
                ]
            },
            "outputs": [],
            "source": [
                "# Pr\u00fcfe, ob die Feature-Namen des Modells mit den Spalten (=Merkmalen) der Eingabedaten X \u00fcbereinstimmen\n",
                "# hier sollte die Ausgabe: \"[ True True True True ]\" erscheinen.\n",
                "print(model.feature_names_in_ == X.columns)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ecef80b8-60da-4534-bc18-770c0b01f88a",
            "metadata": {},
            "source": [
                "Schauen wir uns an, welche Daten wir nun als **Trainingsdaten** haben und wie diese \u00fcber die zwei Merkmale mit den gr\u00f6\u00dften Wichtigkeit im Modell, n\u00e4mlich *petallength* und *petalwidth*, aufgeteilt sind. Daf\u00fcr \u00fcbergeben wir die Trainingsdaten dem *LIME Explainer* und zeichnen diese mit einem *Scatterplot*."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "378bba69-f45c-44c2-a288-d478910d9aa4",
            "metadata": {},
            "outputs": [],
            "source": [
                "ax = iris.loc[X_train.index].plot.scatter('petallength', 'petalwidth', c='class', label= 0,  colormap='viridis')"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ac80b4b9-6158-4eb6-86cb-446598561051",
            "metadata": {},
            "source": [
                "Du siehst, dass die drei Klassen (0 bis 2) der Schwertlilienarten als farbige Punke dargestellt sind. Die Klassen 1 und 2 \u00fcberlappen sich leicht."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "55c6cf36-5aad-4e8c-a699-a59b8b8f9e07",
            "metadata": {},
            "source": [
                "**Schritt 3:** Wir erstellen aus den Trainingsdaten einen *LIME Explainer*. Die Trainingsdaten braucht dieser, um zu erahnen um welche numerischen Bereiche die Merkmale jeweils variieren."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5ee916fa-2989-4b36-88b0-e8c09a764d30",
            "metadata": {},
            "outputs": [],
            "source": [
                "from lime import lime_tabular\n",
                "import numpy as np\n",
                "\n",
                "explainer = lime_tabular.LimeTabularExplainer(\n",
                "    training_data = np.array(X_train),\n",
                "    feature_names = ['sepallength', 'sepalwidth', 'petallength', 'petalwidth'],\n",
                "    class_names   = y_train['class'].unique(),\n",
                "    mode          = 'classification'\n",
                ")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "6ee54d64-429b-441e-b500-0f261e975082",
            "metadata": {},
            "source": [
                "**Schritt 4:** Mit Hilfe dieses *Explainers* k\u00f6nnen wir nun eine konkrete Eingabe dem Modell (Mit Hilfe von dessen `predict_proba`-Methode) \u00fcbergeben. Die neue Eingabe entnehmen wir aus den Testdaten `X_test`.\n",
                "\n",
                "Nehmen wir als erstes Beispiel den Datenpunkt mit dem Index 130:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "5b43f922-6609-4c62-8466-25d21ef2bead",
            "metadata": {},
            "outputs": [],
            "source": [
                "idx = 130\n",
                "np.random.seed(0)\n",
                "exp = explainer.explain_instance(\n",
                "    data_row     = X_test.loc[idx], \n",
                "    predict_fn   = model.predict_proba,\n",
                "    num_features = 2,\n",
                "    top_labels   = 1\n",
                ")\n",
                "exp.show_in_notebook(show_table=True);\n",
                "print(\"Die tats\u00e4chliche Schwertlilienart ist: \", y_test.loc[idx])\n",
                "# Hinweis: Es kann sein, dass du hier eine Fehlermeldung siehst \"UserWarning: X does not have valid feature names...\", die du aber ignorieren darfst ;)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "4e9547f7-3fbc-4b7f-aea9-974ceef33d33",
            "metadata": {},
            "source": [
                "Wir sehen, dass der Datenpunkt mit dem Index 130 zur Schwertlilienart Nummer 2 geh\u00f6rt. Die Grafik (links) zeigt, dass die Vorhersagegenauigkeit f\u00fcr genau diese Klasse bei 1.00 liegt. Die mittlere Grafik zeigt, dass die beiden Merkmale *petellength* und *petalwidth* den gr\u00f6\u00dften Einfluss **f\u00fcr** eine Entscheidung (gr\u00fcn) zur Ausgabe 2 hatten. Das zeigt auch nochmal der die rechte Grafik, die die beiden wichtigsten Features und ihre Werte, die f\u00fcr die Ausgabe 2 gesprochen haben, auflistet.\n",
                "\n",
                "Die mittlere Grafik (oben), die die positiven und negativen Faktoren f\u00fcr die Ausgabe 2 darstellt, k\u00f6nnen wir auch separat wie folgt ausgeben:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "d639b927-305b-4c18-be30-f71bd926508e",
            "metadata": {},
            "outputs": [],
            "source": [
                "fig = exp.as_pyplot_figure(2)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "a1b645fb-edc3-480a-a864-2656a6557298",
            "metadata": {},
            "source": [
                "**Schritt 5:** Schaue dir die Testdaten in einem *Scatterplot* an und suche den obigen Datenpunkt (Index=130)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e786beb0-c870-4226-9b8d-c6c577ae9205",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Wir erzeugen wieder ein Scatterplot - nun mit den Testdaten X_test\n",
                "ax = iris.loc[X_test.index].plot.scatter('petallength', 'petalwidth', c='class', colormap='viridis')\n",
                "# ... und schreiben die Index-Nummer der Datenpunkte dazu...\n",
                "for i,txt in enumerate(X_test.index):\n",
                "    ax.annotate(txt,(X_test.iloc[i]['petallength'],X_test.iloc[i]['petalwidth']))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "0944a3dc-9ad7-4ad6-a24f-60551326bead",
            "metadata": {},
            "source": [
                "Such dir nun einen anderen Punkt heraus, der n\u00e4her an der Grenze zwischen der Klasse 1 und 2 liegt und analysiere ihn dann wie oben. Setze diesen unten im Code ein und pr\u00fcfe die Erkl\u00e4rung. Lass dir diesmal *alle vier* Features (`num_features`) und *alle* Ausgabe-Labels (`top_labels`) anzeigen."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "3bda462a-39ad-4163-9e2c-5e11115db74a",
            "metadata": {
                "tags": [
                    "Aufgabe"
                ]
            },
            "outputs": [],
            "source": [
                "idx = ...\n",
                "exp = explainer.explain_instance(\n",
                "    data_row     = X_test.loc[idx], \n",
                "    predict_fn   = model.predict_proba,\n",
                "    num_features = ...,\n",
                "    top_labels   = ...\n",
                ")\n",
                "exp.show_in_notebook(show_table=True);\n",
                "print(\"Die vorhergesagte Schwertlilienart ist: \", model.predict(X_test.loc[[idx]])[0])\n",
                "print(\"Die tats\u00e4chliche  Schwertlilienart ist: \", y_test.loc[idx][0])\n",
                "\n",
                "fig = exp.as_pyplot_figure(...)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "31da5e47-616f-464b-abd9-b5ad1a2ff6cf",
            "metadata": {
                "tags": [
                    "L\u00f6sung"
                ],
                "jupyter": {
                    "source_hidden": true
                }
            },
            "outputs": [],
            "source": [
                "# Um die L\u00f6sung anzuzeigen, bitte diese Zelle zweimal ausf\u00fchren\n",
                "%load L\u00f6sungen/L\u00f6sung03.py"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "0f64ac1e-1592-4d7b-95ab-cf00a1ceca75",
            "metadata": {
                "tags": [
                    "Aufgabe"
                ]
            },
            "source": [
                "**Frage:** Welche Features haben den gr\u00f6\u00dften Einfluss darauf gehabt, dass der von dir ausgew\u00e4hlte Datenpunkt der richtigen Klasse zugeordnet wurde?"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "ba99fddd-801f-46bf-83a8-0592fce5e48a",
            "metadata": {
                "tags": [
                    "L\u00f6sung"
                ],
                "jupyter": {
                    "source_hidden": true
                }
            },
            "source": [
                "**L\u00f6sungen:**\n",
                "* Beim Datenpunkt **133**: Er geh\u00f6rt zur Klasse 2 und wird auch vom Modell so erkannt.\n",
                "  Obwohl die *petallength* am st\u00e4rksten f\u00fcr Klasse 1 spricht, spricht die *sepalwidth* dagegen. F\u00fcr Klasse 2 sprechen - wenn auch von ihren absoluten Werten kleiner - *sepalwidth* und *petallength*. Dies sieht man, wenn man `exp.as_pyplot_figure(2)` betrachtet.\n",
                "\n",
                "* Beim Datenpunkt  **83**: Er geh\u00f6rt zur Klasse 1, wird aber vom Modell als Klasse 2 vorhergesagt. Warum ist das so?\n",
                "\n",
                "  Beim Betrachten von `exp.as_pyplot_figure(2)`: F\u00fcr die Klasse 2 sprechen die Werte *sepalwidth und petallength* (gr\u00fcn). Allerdings sprechen die beiden anderen Features *sepallength und petalwidth* auch merklich gegen die Klasse 2 (rot).\n",
                "  \n",
                "  Beim Betrachten von `exp.as_pyplot_figure(1)`: F\u00fcr die (falsche) Klasse 1 spricht hier mit gro\u00dfem Anteil insbesondere die *petallength*. *sepalwidth* und *petalwidth* sprechen zwar gegen Klasse 1, doch das Modell gewichtet diese deutlich geringer, so dass sie letztlich die Entscheidung f\u00fcr Klasse 1 nicht beeinflusst haben.\n",
                "  \n",
                "* Beim Datenpunkt  **78**: Er geh\u00f6rt zur Klasse 1 und wird auch vom Modell so erkannt.\n",
                "  Betrachtet man die Einfl\u00fcsse, die f\u00fcr und gegen Klasse 1 bzw. 2 sprechen, erkennt man, dass je zwei Merkmale f\u00fcr bzw. gegen Klasse 2 sprechen. Bei Klasse 1 ist daszwar \u00e4hnlich, doch \u00fcberwiegt hier der Einfluss der *petallength*.\n",
                "  \n",
                "* Beim Datenpunkt  **63**: Die Situation ist sehr \u00e4hnlich zum Datenpunkt 78. Die absoluten Einflussfaktoren aus den Eingabegr\u00f6\u00dfen sprechen ebenso f\u00fcr Klasse 1."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "fd339afa-7274-409c-9bc8-3a5d93118ee9",
            "metadata": {
                "tags": []
            },
            "source": [
                "## Optionale Zusatzaufgabe\n",
                "Als Erg\u00e4nzung zum oben gezeigten LIME-Ansatz schauen wir uns einen anderen Algorithmus an, der auf den sogenannten *Shapley-Values* basiert."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "08a83e15-41ae-4d31-8c3e-a3eb7fbfde2f",
            "metadata": {
                "tags": []
            },
            "source": [
                "### *Hinweis:* \n",
                "Die aktuelle Version von Shap f\u00fcr Python wird nur bis zur Version 3.11 unterst\u00fctzt. Wenn du diese Aufgabe bearbeiten m\u00f6chtest, musst du zuerst deine Python-Version \u00fcberpr\u00fcfen und gegebenenfalls eine \u00e4ltere Python-Version installieren (oder eine andere Umgebung mit Python 3.11 nutzen).\n",
                "\n",
                "**Vorbereitung:** Bevor du *shap* verwenden kannst, muss *shap* installiert werden. \u00d6ffne dazu die Eingabeaufforderung/Terminal (z.B. im Jupyter Notebook \u00fcber File -> New -> Terminal) und installiere *shap* mit `'pip install shap'`. Danach musst du den Python-Kernel neu starten (JupyterLab-Men\u00fc: Kernel --> Restart Kernel ...) und die obigen Code-Teile erneut ausf\u00fchren."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "78770d16-e98d-4ccb-98a9-b10f378af249",
            "metadata": {},
            "source": [
                "### Aufgabe\n",
                "Verwende den SHAP-Ansatz, um das Modell zu erkl\u00e4ren (https://shap.readthedocs.io/en/latest). Wie unterscheidet sich der SHAP-Ansatz vom LIME-Ansatz?"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "5fbc05ea-4731-4129-8627-00b256a6dfb6",
            "metadata": {},
            "source": [
                "Wir gehen dabei in drei Schritten vor: Auch hier m\u00fcssen wir im Code erstmal einen *Explainer* erzeugen. Den wenden wir dann explizit auf Testdaten an, und visualisieren die erhaltenen Ergebnisse.\n",
                "\n",
                "**Schritt 1:** Einen *SHAP-Explainer* erzeugen. Schau dir in der Dokumentation dazu den Teil [Example of loading a custom tree model into SHAP](https://shap.readthedocs.io/en/latest/example_notebooks/tabular_examples/tree_based_models/Example%20of%20loading%20a%20custom%20tree%20model%20into%20SHAP.html) an. Dort ist Python Code eines Jupyter Notebooks gezeigt, bei dem ab Code-Zelle \"\\[6\\]\" das Modell des Entscheidungsbaums f\u00fcr den *Explainer* verwendet wird. Auch wir verwenden den [TreeExplainer](https://shap.readthedocs.io/en/latest/generated/shap.TreeExplainer.html):"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "68615a6c-6fc1-4527-bd4c-88369dc31342",
            "metadata": {},
            "outputs": [],
            "source": [
                "import shap    # wir importieren die 'shap' bibliothek\n",
                "# shap.initjs()   # und initialisieren diese     ... nicht notwendig?\n",
                "shap_explainer = shap.TreeExplainer(model)\n",
                "\n",
                "# Hinweis: Du bekommst evtl. eine Meldung \"IProgress not found. Please update jupyter an ipywidgets...\" - diese darfst du ignorieren ;)."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d790eea4-fff2-4eae-8810-42c851d450e9",
            "metadata": {},
            "source": [
                "**Schritt 2:** Mit Hilfe des `shap_explainer` lassen wir uns nun die *SHAP-Values* zu den Testdaten berechnen:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0257fce7-6ed3-473f-85a0-db8c0424d26f",
            "metadata": {},
            "outputs": [],
            "source": [
                "shap_values = shap_explainer.shap_values(X_test)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "df9d0678-b51f-4113-9f52-6e062c75f350",
            "metadata": {},
            "source": [
                "**Schritt 3:** Diese k\u00f6nnen wir zusammen in einem Diagramm \u00fcber die vier Merkmale darstellen:"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "27568f4d-2b5a-4eb4-994c-6b4ed315571f",
            "metadata": {},
            "outputs": [],
            "source": [
                "figure = plt.figure()\n",
                "shap.summary_plot(shap_values, X_test)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "9f302153-42a3-4567-8710-046ff04cbcf2",
            "metadata": {
                "tags": [
                    "Aufgabe"
                ]
            },
            "source": [
                "**Zwei Fragen dazu:**\n",
                "* Was bedeutet der *SHAP-Value*?\n",
                "* Was ist hier dargestellt?</br>\n",
                "\n",
                "Schaue dir daf\u00fcr das Diagramm, dessen Achsenbeschriftungen und die Legende genau an.\n",
                "Eine guten Einstieg (in englisch) findest du in der Dokumentation der *shap*-Bibliothek im Einf\u00fchrungsabschnitt [Explaining a linear regression model](https://shap.readthedocs.io/en/latest/example_notebooks/overviews/An%20introduction%20to%20explainable%20AI%20with%20Shapley%20values.html#Explaining-a-linear-regression-model)."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "9dc99f12-9235-4614-b0fa-89c8cd810f83",
            "metadata": {
                "tags": [
                    "L\u00f6sung"
                ],
                "jupyter": {
                    "source_hidden": true
                }
            },
            "source": [
                "Die **Shapley-Werte** stellen - einfach ausgedr\u00fcckt - den Einflussfaktor jeweils *eines* einzelnen Merkmals f\u00fcr *einen* bestimmten Datenpunkt auf *eine* bestimmte Ausgabe (das Klassifikationsergebnis) dar. Diese Werte k\u00f6nnen *positiv* sein und unterst\u00fctzen dabei das Klassifikationsergebnis, oder *negativ* und wirken so dem Klassifikationsergebnis entgegen.\n",
                "\n",
                "Sowohl *positive* wie auch *negative* Shapley-Werte haben also Einfluss auf die Ausgabe - dies **h\u00e4ngt jedoch von der prognostizierten Klasse** ab. In unserem Fall, dem obigen Balkendiagramm, sehen wir, dass das Merkmal *sepallength* **keinen** Einfluss auf die Klassifikation hat - wir k\u00f6nnten daher dieses Merkmal aus unseren Features entfernen.</br>\n",
                "Das Merkmal *petallength* hingegen hat **sehr gro\u00dfen** Einfluss auf alle drei m\u00f6glichen Klassifikationsausgaben - zu fast \u00e4hnlich gro\u00dfen Anteilen. Der Einfluss pro Ausgabeklasse - also die L\u00e4nge des jeweiligen Balkens einer Farbe - errechnet sich aus dem **Mittelwert aller Absolutbetr\u00e4ge der *Shapley-Werte***. Es ist also egal ob ein Merkmal \"f\u00fcr\" oder \"gegen\" eine Ausgabe ist.\n",
                "\n",
                "F\u00fcr das Merkmal *petalwidth* siehst du \u00fcbrigens, dass dieses nur zur Bestimmung der Klassen 1 und 2 beitr\u00e4gt (positiv oder negativ ist hier nicht sichtbar), nicht jedoch zur Klasse 0."
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c9f78ca7-7c51-4b13-890c-44ebeb05ddef",
            "metadata": {},
            "source": [
                "***Anmerkung an die Autoren: Sollen wir das auch noch beschreiben? Wir m\u00fcssten hier recht ausholen.. ich w\u00fcrde den Teil lieber erstmal weglassen. K\u00f6nnen wir ja sp\u00e4ter immer noch \"hinterherschieben\"***"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3 (ipykernel)",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.0"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}